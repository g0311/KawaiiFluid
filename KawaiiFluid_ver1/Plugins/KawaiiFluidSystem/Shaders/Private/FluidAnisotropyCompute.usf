// Copyright KawaiiFluid Team. All Rights Reserved.

#include "/Engine/Private/Common.ush"
#include "FluidSpatialHash.ush"
#include "FluidMortonUtils.ush"

//-----------------------------------------------------------------------------
// Anisotropy Compute Shader
// Calculates ellipsoid orientation and scale for each particle
// Based on NVIDIA FleX and Yu & Turk 2013
//-----------------------------------------------------------------------------

// GPU Particle Attachment Structure (must match FGPUParticleAttachment in C++)
struct FGPUParticleAttachment
{
	int PrimitiveType;         // 4 bytes
	int PrimitiveIndex;        // 4 bytes
	int BoneIndex;             // 4 bytes
	float AdhesionStrength;    // 4 bytes
	float3 LocalOffset;        // 12 bytes
	float AttachmentTime;      // 4 bytes
	float3 RelativeVelocity;   // 12 bytes - Velocity relative to bone
	float Padding;             // 4 bytes
};

// Particle Flags (must match EGPUParticleFlags in C++)
#define FLAG_IS_ATTACHED (1 << 0)
#define FLAG_IS_SURFACE (1 << 1)
#define FLAG_IS_CORE (1 << 2)
#define FLAG_JUST_DETACHED (1 << 3)

// Anisotropy Mode
#define MODE_VELOCITY_BASED 0
#define MODE_DENSITY_BASED 1
#define MODE_HYBRID 2

// SoA (Structure of Arrays) Particle Buffers
Buffer<float> InPositions;               // [ParticleCount * 3] float3 as 3 consecutive floats
Buffer<float> InVelocities;              // [ParticleCount * 3] float3 as 3 consecutive floats
Buffer<uint> InFlags;                    // [ParticleCount] uint

// Input: Attachment buffer (for surface normal of attached particles)
StructuredBuffer<FGPUParticleAttachment> InAttachments;

// Spatial Hash buffers (for DensityBased mode)
// TODO(KHJ): Remove legacy hash-based lookup - bUseZOrderSorting is always true
// Legacy hash-based lookup (random access pattern)
StructuredBuffer<uint> CellCounts;
StructuredBuffer<uint> ParticleIndices;

// Morton-sorted lookup (sequential access pattern, cache-friendly)
// When bUseZOrderSorting=1, ParticleBuffer is already sorted by Morton code
// CellStart/CellEnd give contiguous ranges in the sorted buffer
StructuredBuffer<uint> CellStart;           // CellStart[cellID] = first particle index in sorted array
StructuredBuffer<uint> CellEnd;             // CellEnd[cellID] = last particle index in sorted array

// Output: Anisotropy SoA buffers (float4 = direction.xyz + scale.w)
RWStructuredBuffer<float4> OutAnisotropyAxis1;
RWStructuredBuffer<float4> OutAnisotropyAxis2;
RWStructuredBuffer<float4> OutAnisotropyAxis3;

// Parameters
uint ParticleCount;
uint AnisotropyMode;  // 0=Velocity, 1=Density, 2=Hybrid
float VelocityStretchFactor;
float AnisotropyScale;
float AnisotropyMin;
float AnisotropyMax;
float DensityWeight;  // For Hybrid mode
float SmoothingRadius;
float CellSize;
// TODO(KHJ): Remove bUseZOrderSorting - always true, legacy path is dead code
int bUseZOrderSorting;  // 1 = use Morton-sorted CellStart/End, 0 = use legacy CellCounts

// Attached particle anisotropy params
float AttachedFlattenScale;   // How flat (0.3 = 30% height along normal)
float AttachedStretchScale;   // Perpendicular stretch (1.5 = 150%)

// Morton code parameters (for Z-Order sorting mode)
float3 MortonBoundsMin;       // Grid origin for Morton code calculation
int bUseHybridTiledZOrder;    // 1 = Hybrid Tiled Z-Order (unlimited range), 0 = Classic Morton

//-----------------------------------------------------------------------------
// Boundary Particles for anisotropy calculation (Akinci 2012 style)
//-----------------------------------------------------------------------------
struct FGPUBoundaryParticle
{
	float3 Position;      // 12 bytes - World position
	float Psi;            // 4 bytes  - Boundary particle "mass" (total: 16)
	float3 Normal;        // 12 bytes - Surface normal
	int OwnerID;          // 4 bytes  - Owner component ID (total: 32)
	float3 Velocity;      // 12 bytes - World velocity
	float FrictionCoeff;  // 4 bytes  - Coulomb friction coefficient (total: 48)
	int BoneIndex;        // 4 bytes  - Skeleton bone index (-1 for static mesh)
	float3 Padding;       // 12 bytes - Alignment padding (total: 64)
};

// Legacy brute-force mode
StructuredBuffer<FGPUBoundaryParticle> BoundaryParticles;
int BoundaryParticleCount;
int bUseBoundaryAnisotropy;

// Z-Order sorted mode (cache-friendly)
StructuredBuffer<FGPUBoundaryParticle> SortedBoundaryParticles;
StructuredBuffer<uint> BoundaryCellStart;
StructuredBuffer<uint> BoundaryCellEnd;
int bUseBoundaryZOrder;
float BoundaryWeight;

// Temporal Smoothing
StructuredBuffer<float4> PrevAnisotropyAxis1;
StructuredBuffer<float4> PrevAnisotropyAxis2;
StructuredBuffer<float4> PrevAnisotropyAxis3;
int bEnableTemporalSmoothing;
float TemporalSmoothFactor;
int bHasPreviousFrame;

//-----------------------------------------------------------------------------
// Z-Order Cell ID Calculation (uses shader parameters)
// Morton code functions are provided by FluidMortonUtils.ush
//-----------------------------------------------------------------------------

// Compute cell ID from cell coordinates (integer)
// Supports both Hybrid Tiled Z-Order (unlimited range) and Classic Morton (bounded)
// This version uses shader parameters (MortonBoundsMin, CellSize, bUseHybridTiledZOrder) directly.
uint GetMortonCellIDFromCellCoord_Aniso(int3 cellCoord)
{
	if (bUseHybridTiledZOrder)
	{
		// Hybrid Tiled Z-Order: 21-bit key (3-bit TileHash + 18-bit LocalMorton)
		// Matches MAX_CELLS, so mask is a no-op but kept for consistency
		// Hash collisions (8 tile buckets) are filtered by distance check
		return ComputeHybridTiledKey(cellCoord) & (MAX_CELLS - 1);
	}
	else
	{
		// Classic Morton code: bounded range
		// Compute grid minimum cell (same as in FluidMortonCode.usf)
		int3 gridMin = int3(floor(MortonBoundsMin / CellSize));

		// Offset cell coordinates to make them positive (relative to grid min)
		int3 offset = cellCoord - gridMin;

		// Clamp to valid range for current preset
		uint3 uoffset = uint3(max(offset, int3(0, 0, 0)));
		uoffset = min(uoffset, uint3(MORTON_MAX_VALUE, MORTON_MAX_VALUE, MORTON_MAX_VALUE));

		// Compute Morton code using preset-specific function from FluidMortonUtils.ush
		return Morton3D(uoffset.x, uoffset.y, uoffset.z);
	}
}

//-----------------------------------------------------------------------------
// FleX / Yu & Turk Style Constants
//-----------------------------------------------------------------------------

// Eigenvalue ratio clamping (prevents too-thin ellipsoids)
// kr = 4 means minimum scale is 25% of maximum (FleX style, more rounded)
#define K_R 4.0f

// Minimum neighbors for covariance calculation (PCA requires at least 4)
#define MIN_NEIGHBORS_FOR_ANISOTROPY 4

// Neighbor count for full anisotropy (surface particles typically have ~6+)
// At MIN(4): sphere, At FULL(6): complete anisotropy
#define FULL_NEIGHBORS_FOR_ANISOTROPY 6

// Stretch multiplier to make ellipsoids visually elongated
// FleX uses 1.0 (no extra multiplier) - higher values cause edge artifacts
#define STRETCH_MULTIPLIER 1.0f

//-----------------------------------------------------------------------------
// Helper: Build orthonormal basis from direction (Frisvad's method)
//-----------------------------------------------------------------------------
void BuildOrthonormalBasis(float3 N, out float3 T, out float3 B)
{
	if (N.z < -0.9999999f)
	{
		T = float3(0.0f, -1.0f, 0.0f);
		B = float3(-1.0f, 0.0f, 0.0f);
	}
	else
	{
		float A = 1.0f / (1.0f + N.z);
		float D = -N.x * N.y * A;
		T = float3(1.0f - N.x * N.x * A, D, -N.x);
		B = float3(D, 1.0f - N.y * N.y * A, -N.y);
	}
}

//-----------------------------------------------------------------------------
// Helper: SPH Kernel weight (cubic spline)
//-----------------------------------------------------------------------------
float KernelWeight(float Distance, float H)
{
	if (Distance >= H)
	{
		return 0.0f;
	}

	float Q = Distance / H;
	if (Q < 0.5f)
	{
		return 1.0f - 6.0f * Q * Q + 6.0f * Q * Q * Q;
	}
	else
	{
		float OneMinusQ = 1.0f - Q;
		return 2.0f * OneMinusQ * OneMinusQ * OneMinusQ;
	}
}

//-----------------------------------------------------------------------------
// Helper: 3x3 Symmetric Eigenvalue Decomposition (Analytical - Cardano's formula)
// OPTIMIZED: No iteration, direct analytical solution
// Reference: "Eigenvalues of a 3x3 symmetric matrix" - Kopp (2008)
//-----------------------------------------------------------------------------

// Compute eigenvector for a given eigenvalue using cross product method
float3 ComputeEigenvector(float3x3 A, float eigenvalue)
{
	// (A - λI) should have rank 2, so we find null space
	float3 row0 = float3(A[0][0] - eigenvalue, A[0][1], A[0][2]);
	float3 row1 = float3(A[1][0], A[1][1] - eigenvalue, A[1][2]);
	float3 row2 = float3(A[2][0], A[2][1], A[2][2] - eigenvalue);

	// Cross product of two rows gives eigenvector (perpendicular to both)
	float3 cross01 = cross(row0, row1);
	float3 cross12 = cross(row1, row2);
	float3 cross02 = cross(row0, row2);

	// Pick the cross product with largest magnitude for numerical stability
	float len01 = dot(cross01, cross01);
	float len12 = dot(cross12, cross12);
	float len02 = dot(cross02, cross02);

	float3 eigenvec;
	if (len01 >= len12 && len01 >= len02)
	{
		eigenvec = cross01;
	}
	else if (len12 >= len01 && len12 >= len02)
	{
		eigenvec = cross12;
	}
	else
	{
		eigenvec = cross02;
	}

	float len = length(eigenvec);
	if (len > 1e-10f)
	{
		return eigenvec / len;
	}

	// Fallback for degenerate case
	return float3(1, 0, 0);
}

void SymmetricEigen3x3(
	float3x3 M,
	out float3 EigenValues,
	out float3 EigenVec0,
	out float3 EigenVec1,
	out float3 EigenVec2)
{
	// Diagonal and off-diagonal elements
	float m00 = M[0][0], m11 = M[1][1], m22 = M[2][2];
	float m01 = M[0][1], m02 = M[0][2], m12 = M[1][2];

	// Check if already diagonal (common case for sparse distributions)
	float offDiagSq = m01*m01 + m02*m02 + m12*m12;
	if (offDiagSq < 1e-12f)
	{
		// Already diagonal - eigenvalues are diagonal elements
		// Sort descending
		if (m00 >= m11 && m00 >= m22)
		{
			EigenValues.x = m00;
			EigenVec0 = float3(1, 0, 0);
			if (m11 >= m22)
			{
				EigenValues.y = m11;
				EigenValues.z = m22;
				EigenVec1 = float3(0, 1, 0);
				EigenVec2 = float3(0, 0, 1);
			}
			else
			{
				EigenValues.y = m22;
				EigenValues.z = m11;
				EigenVec1 = float3(0, 0, 1);
				EigenVec2 = float3(0, 1, 0);
			}
		}
		else if (m11 >= m00 && m11 >= m22)
		{
			EigenValues.x = m11;
			EigenVec0 = float3(0, 1, 0);
			if (m00 >= m22)
			{
				EigenValues.y = m00;
				EigenValues.z = m22;
				EigenVec1 = float3(1, 0, 0);
				EigenVec2 = float3(0, 0, 1);
			}
			else
			{
				EigenValues.y = m22;
				EigenValues.z = m00;
				EigenVec1 = float3(0, 0, 1);
				EigenVec2 = float3(1, 0, 0);
			}
		}
		else
		{
			EigenValues.x = m22;
			EigenVec0 = float3(0, 0, 1);
			if (m00 >= m11)
			{
				EigenValues.y = m00;
				EigenValues.z = m11;
				EigenVec1 = float3(1, 0, 0);
				EigenVec2 = float3(0, 1, 0);
			}
			else
			{
				EigenValues.y = m11;
				EigenValues.z = m00;
				EigenVec1 = float3(0, 1, 0);
				EigenVec2 = float3(1, 0, 0);
			}
		}
		return;
	}

	// =========================================================================
	// Cardano's formula for eigenvalues of 3x3 symmetric matrix
	// Characteristic polynomial: λ³ - c2*λ² + c1*λ - c0 = 0
	// =========================================================================

	// Invariants of the matrix
	float trace = m00 + m11 + m22;
	float q = trace / 3.0f;

	// Shift matrix by q to make it traceless: B = A - q*I
	float b00 = m00 - q;
	float b11 = m11 - q;
	float b22 = m22 - q;

	// p² = (1/6) * (sum of squares of B elements) * 2
	// For symmetric: p² = (1/6) * (b00² + b11² + b22² + 2*(m01² + m02² + m12²))
	float p2 = (b00*b00 + b11*b11 + b22*b22 + 2.0f * offDiagSq) / 6.0f;

	if (p2 < 1e-12f)
	{
		// Matrix is q*I (all eigenvalues equal)
		EigenValues = float3(q, q, q);
		EigenVec0 = float3(1, 0, 0);
		EigenVec1 = float3(0, 1, 0);
		EigenVec2 = float3(0, 0, 1);
		return;
	}

	float p = sqrt(p2);

	// Determinant of B/p (scaled shifted matrix)
	// det(B) = b00*(b11*b22 - m12²) - m01*(m01*b22 - m12*m02) + m02*(m01*m12 - b11*m02)
	float detB = b00 * (b11*b22 - m12*m12)
	           - m01 * (m01*b22 - m12*m02)
	           + m02 * (m01*m12 - b11*m02);

	// r = det(B/p) / 2 = det(B) / (2 * p³)
	float r = detB / (2.0f * p * p * p);

	// Clamp r to [-1, 1] for numerical stability
	r = clamp(r, -1.0f, 1.0f);

	// Angle for Cardano's formula
	float phi = acos(r) / 3.0f;

	// Three eigenvalues (sorted descending)
	// λk = q + 2*p*cos(φ + 2πk/3) for k = 0, 1, 2
	const float TWO_PI_OVER_3 = 2.0943951f;  // 2π/3

	float lambda0 = q + 2.0f * p * cos(phi);
	float lambda2 = q + 2.0f * p * cos(phi + TWO_PI_OVER_3);
	float lambda1 = 3.0f * q - lambda0 - lambda2;  // trace = sum of eigenvalues

	// Eigenvalues are already sorted: lambda0 >= lambda1 >= lambda2
	EigenValues = float3(lambda0, lambda1, lambda2);

	// =========================================================================
	// Compute eigenvectors using cross product method
	// =========================================================================
	EigenVec0 = ComputeEigenvector(M, lambda0);

	// For second eigenvector, ensure orthogonality to first
	EigenVec1 = ComputeEigenvector(M, lambda1);
	// Gram-Schmidt orthogonalization
	EigenVec1 = EigenVec1 - dot(EigenVec1, EigenVec0) * EigenVec0;
	float len1 = length(EigenVec1);
	if (len1 > 1e-10f)
	{
		EigenVec1 /= len1;
	}
	else
	{
		// Degenerate: build orthogonal vector
		BuildOrthonormalBasis(EigenVec0, EigenVec1, EigenVec2);
		return;
	}

	// Third eigenvector is cross product of first two (guaranteed orthogonal)
	EigenVec2 = cross(EigenVec0, EigenVec1);
}

//-----------------------------------------------------------------------------
// Velocity-Based Anisotropy (with explicit velocity parameter)
// Volume-preserving using log-space processing
//-----------------------------------------------------------------------------
void CalculateVelocityBasedWithVelocity(
	float3 Velocity,
	out float3 Axis1, out float3 Axis2, out float3 Axis3,
	out float Scale1, out float Scale2, out float Scale3)
{
	// Default: identity (sphere)
	Axis1 = float3(1, 0, 0);
	Axis2 = float3(0, 1, 0);
	Axis3 = float3(0, 0, 1);
	Scale1 = Scale2 = Scale3 = 1.0f;

	float Speed = length(Velocity);

	if (Speed > 0.001f)
	{
		Axis1 = Velocity / Speed;
		BuildOrthonormalBasis(Axis1, Axis2, Axis3);

		// Calculate stretch in log space for volume preservation
		// Stretch along velocity: LogScale1 = log(1 + Speed * Stretch)
		// Perpendicular compression: LogScale2 = LogScale3 = -LogScale1 / 2 (volume = 1.0)
		float Stretch = VelocityStretchFactor * AnisotropyScale;
		float RawScale1 = 1.0f + Speed * Stretch;

		// Convert to log space
		float LogScale1 = log(max(RawScale1, 0.001f));
		// Volume preservation: LogScale1 + 2*LogScale2 = 0 => LogScale2 = -LogScale1/2
		float LogScale2 = -LogScale1 * 0.5f;
		float LogScale3 = LogScale2;

		// Clamp in log space
		float LogMin = log(max(AnisotropyMin, 0.001f));
		float LogMax = log(max(AnisotropyMax, 0.001f));
		LogScale1 = clamp(LogScale1, LogMin, LogMax);
		LogScale2 = clamp(LogScale2, LogMin, LogMax);
		LogScale3 = clamp(LogScale3, LogMin, LogMax);

		// Re-center logs to maintain volume = 1.0
		float LogSum = LogScale1 + LogScale2 + LogScale3;
		float LogAvg = LogSum / 3.0f;
		LogScale1 -= LogAvg;
		LogScale2 -= LogAvg;
		LogScale3 -= LogAvg;

		// Convert back to linear space
		Scale1 = exp(LogScale1);
		Scale2 = exp(LogScale2);
		Scale3 = exp(LogScale3);
	}
}

// Wrapper for backward compatibility
void CalculateVelocityBased(
	uint ParticleIndex,
	out float3 Axis1, out float3 Axis2, out float3 Axis3,
	out float Scale1, out float Scale2, out float Scale3)
{
	uint idx3 = ParticleIndex * 3;
	float3 velocity = float3(InVelocities[idx3], InVelocities[idx3 + 1], InVelocities[idx3 + 2]);
	CalculateVelocityBasedWithVelocity(velocity, Axis1, Axis2, Axis3, Scale1, Scale2, Scale3);
}

//-----------------------------------------------------------------------------
// Density-Based Anisotropy (Covariance Matrix)
// NVIDIA FleX Style with Local Caching Optimization
// Pass 1: Single memory traversal - cache neighbors + compute SmoothedCenter
// Pass 2: Compute covariance from LOCAL CACHE (no memory access)
// This prevents jittering and avoids double memory traversal
//-----------------------------------------------------------------------------

// Maximum cached neighbors per particle (typical PBF has ~20-40 neighbors)
// NOTE: Keep this small (32) to avoid GPU register spilling. 64 causes ~50% slowdown.
#define MAX_CACHED_NEIGHBORS 32

void CalculateDensityBased(
	uint ParticleIndex,
	out float3 Axis1, out float3 Axis2, out float3 Axis3,
	out float Scale1, out float Scale2, out float Scale3,
	out int OutNeighborCount)
{
	// Default: identity (sphere with scale 1.0, NOT AnisotropyScale)
	Axis1 = float3(1, 0, 0);
	Axis2 = float3(0, 1, 0);
	Axis3 = float3(0, 0, 1);
	Scale1 = Scale2 = Scale3 = 1.0f;
	OutNeighborCount = 0;

	uint idx3 = ParticleIndex * 3;
	float3 CenterPos = float3(InPositions[idx3], InPositions[idx3 + 1], InPositions[idx3 + 2]);

	int3 CenterCell = WorldToCell(CenterPos, CellSize);
	int CellRadius = (int)ceil(SmoothingRadius / CellSize);
	float H2 = SmoothingRadius * SmoothingRadius;

	// =========================================================================
	// Local cache for neighbor data (avoids second memory traversal)
	// =========================================================================
	float3 CachedPositions[MAX_CACHED_NEIGHBORS];
	float CachedWeights[MAX_CACHED_NEIGHBORS];
	int CachedCount = 0;

	// =========================================================================
	// PASS 1: Single memory traversal - cache neighbors + compute SmoothedCenter
	// =========================================================================
	float3 SumWP = float3(0, 0, 0);
	float SumW = 0.0f;
	int NeighborCount = 0;

	if (bUseZOrderSorting)
	{
		for (int dz = -CellRadius; dz <= CellRadius; ++dz)
		{
			for (int dy = -CellRadius; dy <= CellRadius; ++dy)
			{
				for (int dx = -CellRadius; dx <= CellRadius; ++dx)
				{
					int3 NeighborCell = CenterCell + int3(dx, dy, dz);
					uint CellID = GetMortonCellIDFromCellCoord_Aniso(NeighborCell);
					uint Start = CellStart[CellID];
					uint End = CellEnd[CellID];

					if (Start == INVALID_INDEX || End == INVALID_INDEX)
					{
						continue;
					}

					End = min(End, (uint)(ParticleCount - 1));

					for (uint NeighborIdx = Start; NeighborIdx <= End; ++NeighborIdx)
					{
						if (NeighborIdx >= ParticleCount)
						{
							continue;
						}

						uint neighborIdx3 = NeighborIdx * 3;
						float3 NeighborPos = float3(InPositions[neighborIdx3], InPositions[neighborIdx3 + 1], InPositions[neighborIdx3 + 2]);
						float3 Diff = NeighborPos - CenterPos;
						float Dist2 = dot(Diff, Diff);

						if (Dist2 < H2)
						{
							float Dist = sqrt(Dist2);
							float W = KernelWeight(Dist, SmoothingRadius);

							if (W > 0.0001f)
							{
								// Accumulate for SmoothedCenter
								SumWP += W * NeighborPos;
								SumW += W;
								NeighborCount++;

								// Cache for Pass 2 (avoid overflow)
								if (CachedCount < MAX_CACHED_NEIGHBORS)
								{
									CachedPositions[CachedCount] = NeighborPos;
									CachedWeights[CachedCount] = W;
									CachedCount++;
								}
							}
						}
					}
				}
			}
		}
	}
	else
	{
		for (int dz = -CellRadius; dz <= CellRadius; ++dz)
		{
			for (int dy = -CellRadius; dy <= CellRadius; ++dy)
			{
				for (int dx = -CellRadius; dx <= CellRadius; ++dx)
				{
					int3 NeighborCell = CenterCell + int3(dx, dy, dz);
					uint Hash = HashCell(NeighborCell);
					uint Count = min(CellCounts[Hash], (uint)MAX_PARTICLES_PER_CELL);
					uint BaseIdx = Hash * MAX_PARTICLES_PER_CELL;

					for (uint i = 0; i < Count; ++i)
					{
						uint NeighborIdx = ParticleIndices[BaseIdx + i];
						if (NeighborIdx >= ParticleCount)
						{
							continue;
						}

						uint neighborIdx3 = NeighborIdx * 3;
						float3 NeighborPos = float3(InPositions[neighborIdx3], InPositions[neighborIdx3 + 1], InPositions[neighborIdx3 + 2]);
						float3 Diff = NeighborPos - CenterPos;
						float Dist2 = dot(Diff, Diff);

						if (Dist2 < H2)
						{
							float Dist = sqrt(Dist2);
							float W = KernelWeight(Dist, SmoothingRadius);

							if (W > 0.0001f)
							{
								SumWP += W * NeighborPos;
								SumW += W;
								NeighborCount++;

								if (CachedCount < MAX_CACHED_NEIGHBORS)
								{
									CachedPositions[CachedCount] = NeighborPos;
									CachedWeights[CachedCount] = W;
									CachedCount++;
								}
							}
						}
					}
				}
			}
		}
	}

	OutNeighborCount = NeighborCount;

	// Need minimum neighbors for reliable covariance
	if (NeighborCount < MIN_NEIGHBORS_FOR_ANISOTROPY || SumW < 0.0001f)
	{
		return;
	}

	// Compute Smoothed Position (weighted average)
	float3 SmoothedCenter = SumWP / SumW;

	// =========================================================================
	// PASS 2: Compute Covariance from LOCAL CACHE (no memory access!)
	// This is the key optimization - we read from registers/local memory
	// =========================================================================
	float SumWXX_00 = 0, SumWXX_01 = 0, SumWXX_02 = 0;
	float SumWXX_11 = 0, SumWXX_12 = 0, SumWXX_22 = 0;
	float TotalWeight = 0.0f;

	for (int ci = 0; ci < CachedCount; ++ci)
	{
		float3 NeighborPos = CachedPositions[ci];
		float W = CachedWeights[ci];

		// Use offset from SmoothedCenter (FleX style)
		float3 Offset = NeighborPos - SmoothedCenter;

		TotalWeight += W;

		SumWXX_00 += W * Offset.x * Offset.x;
		SumWXX_01 += W * Offset.x * Offset.y;
		SumWXX_02 += W * Offset.x * Offset.z;
		SumWXX_11 += W * Offset.y * Offset.y;
		SumWXX_12 += W * Offset.y * Offset.z;
		SumWXX_22 += W * Offset.z * Offset.z;
	}

	// =========================================================================
	// Boundary Particle contribution to covariance (Akinci 2012 style + FleX)
	// Boundary particles contribute to the covariance matrix to influence
	// ellipsoid orientation near surfaces
	// Also uses SmoothedCenter for stability
	// =========================================================================
	if (bUseBoundaryAnisotropy && BoundaryParticleCount > 0)
	{
		if (bUseBoundaryZOrder)
		{
			// =================================================================
			// Z-Order Mode: O(K) neighbor search using Morton code
			// =================================================================
			for (int dz = -CellRadius; dz <= CellRadius; ++dz)
			{
				for (int dy = -CellRadius; dy <= CellRadius; ++dy)
				{
					for (int dx = -CellRadius; dx <= CellRadius; ++dx)
					{
						int3 NeighborCell = CenterCell + int3(dx, dy, dz);
						uint CellID = GetMortonCellIDFromCellCoord_Aniso(NeighborCell);
						uint BStart = BoundaryCellStart[CellID];
						uint BEnd = BoundaryCellEnd[CellID];

						// Skip empty cells
						if (BStart == INVALID_INDEX || BEnd == INVALID_INDEX)
						{
							continue;
						}

						// Sequential access through sorted boundary particles
						for (uint bi = BStart; bi <= BEnd; ++bi)
						{
							FGPUBoundaryParticle boundary = SortedBoundaryParticles[bi];
							float3 Diff = boundary.Position - CenterPos;
							float Dist2 = dot(Diff, Diff);

							if (Dist2 < H2)
							{
								float Dist = sqrt(Dist2);
								float W = KernelWeight(Dist, SmoothingRadius) * BoundaryWeight;

								if (W > 0.0001f)
								{
									// Use offset from SmoothedCenter (FleX style)
									float3 Offset = boundary.Position - SmoothedCenter;

									TotalWeight += W;

									SumWXX_00 += W * Offset.x * Offset.x;
									SumWXX_01 += W * Offset.x * Offset.y;
									SumWXX_02 += W * Offset.x * Offset.z;
									SumWXX_11 += W * Offset.y * Offset.y;
									SumWXX_12 += W * Offset.y * Offset.z;
									SumWXX_22 += W * Offset.z * Offset.z;
								}
							}
						}
					}
				}
			}
		}
		else
		{
			// =================================================================
			// Legacy Mode: O(M) brute-force
			// =================================================================
			for (int bi = 0; bi < BoundaryParticleCount; ++bi)
			{
				FGPUBoundaryParticle boundary = BoundaryParticles[bi];
				float3 Diff = boundary.Position - CenterPos;
				float Dist2 = dot(Diff, Diff);

				if (Dist2 < H2)
				{
					float Dist = sqrt(Dist2);
					float W = KernelWeight(Dist, SmoothingRadius) * BoundaryWeight;

					if (W > 0.0001f)
					{
						// Use offset from SmoothedCenter (FleX style)
						float3 Offset = boundary.Position - SmoothedCenter;

						TotalWeight += W;

						SumWXX_00 += W * Offset.x * Offset.x;
						SumWXX_01 += W * Offset.x * Offset.y;
						SumWXX_02 += W * Offset.x * Offset.z;
						SumWXX_11 += W * Offset.y * Offset.y;
						SumWXX_12 += W * Offset.y * Offset.z;
						SumWXX_22 += W * Offset.z * Offset.z;
					}
				}
			}
		}
	}

	// Need minimum weight for reliable covariance
	if (TotalWeight < 0.0001f)
	{
		return;
	}

	// =========================================================================
	// FleX Style: Covariance already computed relative to SmoothedCenter
	// No need for parallel variance formula - direct covariance matrix
	// =========================================================================
	float InvW = 1.0f / TotalWeight;

	// Covariance = Σ(wi * Offset * Offset^T) / Σwi
	// Offset is already relative to SmoothedCenter, so this is the covariance directly
	float3x3 CovMatrix;
	CovMatrix[0][0] = SumWXX_00 * InvW;
	CovMatrix[0][1] = SumWXX_01 * InvW;
	CovMatrix[0][2] = SumWXX_02 * InvW;
	CovMatrix[1][0] = CovMatrix[0][1];  // Symmetric
	CovMatrix[1][1] = SumWXX_11 * InvW;
	CovMatrix[1][2] = SumWXX_12 * InvW;
	CovMatrix[2][0] = CovMatrix[0][2];  // Symmetric
	CovMatrix[2][1] = CovMatrix[1][2];  // Symmetric
	CovMatrix[2][2] = SumWXX_22 * InvW;

	// Eigenvalue decomposition
	float3 EigenValues;
	float3 EV0, EV1, EV2;
	SymmetricEigen3x3(CovMatrix, EigenValues, EV0, EV1, EV2);

	// Convert to standard deviations
	float Sigma0 = sqrt(max(EigenValues.x, 0.0001f));
	float Sigma1 = sqrt(max(EigenValues.y, 0.0001f));
	float Sigma2 = sqrt(max(EigenValues.z, 0.0001f));

	// Yu & Turk eigenvalue ratio clamping (prevent too thin ellipsoids)
	float MinSigma = Sigma0 / K_R;
	Sigma1 = max(Sigma1, MinSigma);
	Sigma2 = max(Sigma2, MinSigma);

	// =========================================================================
	// Yu & Turk Volume-Preserving Scale Calculation
	// Use geometric mean normalization: Scale1 * Scale2 * Scale3 = 1.0
	// =========================================================================
	float GeoMean = pow(Sigma0 * Sigma1 * Sigma2, 1.0f / 3.0f);

	// Prevent division by zero
	if (GeoMean < 0.0001f)
	{
		GeoMean = 1.0f;
	}

	// Normalized scales (volume = 1.0 guaranteed)
	float EllipsoidScale1 = Sigma0 / GeoMean;
	float EllipsoidScale2 = Sigma1 / GeoMean;
	float EllipsoidScale3 = Sigma2 / GeoMean;

	// =========================================================================
	// Volume-Preserving Log-Space Processing
	// All operations in log space preserve geometric mean (volume = 1.0)
	// Key insight: log(a) + log(b) + log(c) = 0  <=>  a * b * c = 1.0
	// =========================================================================

	// Step 1: Convert to log space
	float LogScale1 = log(max(EllipsoidScale1, 0.001f));
	float LogScale2 = log(max(EllipsoidScale2, 0.001f));
	float LogScale3 = log(max(EllipsoidScale3, 0.001f));

	// Step 2: Apply AnisotropyScale (amplify/dampen ratios)
	// - AnisotropyScale = 0: sphere (all logs become 0)
	// - AnisotropyScale = 1: original ratios
	// - AnisotropyScale > 1: more extreme anisotropy
	LogScale1 *= AnisotropyScale;
	LogScale2 *= AnisotropyScale;
	LogScale3 *= AnisotropyScale;

	// Step 3: Clamp in log space to prevent extreme shapes
	float LogMin = log(max(AnisotropyMin, 0.001f));
	float LogMax = log(max(AnisotropyMax, 0.001f));
	LogScale1 = clamp(LogScale1, LogMin, LogMax);
	LogScale2 = clamp(LogScale2, LogMin, LogMax);
	LogScale3 = clamp(LogScale3, LogMin, LogMax);

	// Step 4: Re-center logs to maintain volume = 1.0 (sum of logs = 0)
	float LogSum = LogScale1 + LogScale2 + LogScale3;
	float LogAvg = LogSum / 3.0f;
	LogScale1 -= LogAvg;
	LogScale2 -= LogAvg;
	LogScale3 -= LogAvg;

	// Step 5: Neighbor-count based blending
	// Surface particles (fewer neighbors) get partial anisotropy
	// Internal particles (more neighbors) get full anisotropy
	float BlendFactor = saturate(
		(float)(NeighborCount - MIN_NEIGHBORS_FOR_ANISOTROPY) /
		(float)(FULL_NEIGHBORS_FOR_ANISOTROPY - MIN_NEIGHBORS_FOR_ANISOTROPY)
	);
	// Lerp in log space: sphere has log scales of (0, 0, 0)
	LogScale1 *= BlendFactor;
	LogScale2 *= BlendFactor;
	LogScale3 *= BlendFactor;

	// Step 6: Convert back to linear space
	Scale1 = exp(LogScale1);
	Scale2 = exp(LogScale2);
	Scale3 = exp(LogScale3);

	// Eigenvectors as axes
	Axis1 = normalize(EV0);
	Axis2 = normalize(EV1);
	Axis3 = normalize(EV2);
}

//-----------------------------------------------------------------------------
// Apply Velocity Stretching to existing ellipsoid
// Stretches the ellipsoid along velocity direction (Yu & Turk style)
//-----------------------------------------------------------------------------
void ApplyVelocityStretching(
	uint ParticleIndex,
	inout float3 Axis1, inout float3 Axis2, inout float3 Axis3,
	inout float Scale1, inout float Scale2, inout float Scale3)
{
	uint idx3 = ParticleIndex * 3;
	float3 velocity = float3(InVelocities[idx3], InVelocities[idx3 + 1], InVelocities[idx3 + 2]);
	float Speed = length(velocity);

	if (Speed < 0.001f)
	{
		return;
	}

	float3 VelDir = velocity / Speed;

	// Calculate velocity stretch factor
	float VelStretch = 1.0f + Speed * VelocityStretchFactor * AnisotropyScale;
	VelStretch = clamp(VelStretch, 1.0f, AnisotropyMax);

	// Project velocity onto each axis and stretch accordingly
	float Proj1 = abs(dot(VelDir, Axis1));
	float Proj2 = abs(dot(VelDir, Axis2));
	float Proj3 = abs(dot(VelDir, Axis3));

	// Apply stretch proportionally to projection
	Scale1 *= lerp(1.0f, VelStretch, Proj1);
	Scale2 *= lerp(1.0f, VelStretch, Proj2);
	Scale3 *= lerp(1.0f, VelStretch, Proj3);

	// Re-clamp scales
	Scale1 = clamp(Scale1, AnisotropyMin, AnisotropyMax);
	Scale2 = clamp(Scale2, AnisotropyMin, AnisotropyMax);
	Scale3 = clamp(Scale3, AnisotropyMin, AnisotropyMax);

	// Volume preservation after velocity stretching
	float VelVolume = Scale1 * Scale2 * Scale3;
	if (VelVolume > 0.001f && abs(VelVolume - 1.0f) > 0.001f)
	{
		float VelVolumeNorm = pow(VelVolume, 1.0f / 3.0f);
		Scale1 /= VelVolumeNorm;
		Scale2 /= VelVolumeNorm;
		Scale3 /= VelVolumeNorm;
	}
}

//-----------------------------------------------------------------------------
// Attached Particle Anisotropy (DISABLED - SurfaceNormal not in struct)
// TODO: Add SurfaceNormal to FGPUParticleAttachment if needed
//-----------------------------------------------------------------------------
/*
void CalculateAttachedAnisotropy(
	uint ParticleIndex,
	out float3 Axis1, out float3 Axis2, out float3 Axis3,
	out float Scale1, out float Scale2, out float Scale3)
{
	// Default: identity (sphere)
	Axis1 = float3(1, 0, 0);
	Axis2 = float3(0, 1, 0);
	Axis3 = float3(0, 0, 1);
	Scale1 = Scale2 = Scale3 = 1.0f;

	// Read surface normal from attachment data
	FGPUParticleAttachment Attachment = InAttachments[ParticleIndex];
	float3 SurfaceNormal = Attachment.SurfaceNormal;

	// Validate normal
	float NormalLen = length(SurfaceNormal);
	if (NormalLen < 0.001f)
	{
		// Invalid normal, use up vector as fallback
		SurfaceNormal = float3(0, 0, 1);
	}
	else
	{
		SurfaceNormal = SurfaceNormal / NormalLen;
	}

	// Build orthonormal basis with normal as Axis3 (shortest axis)
	// Normal direction = flattened direction (smallest scale)
	Axis3 = SurfaceNormal;
	BuildOrthonormalBasis(Axis3, Axis1, Axis2);

	// Apply flattening: normal direction gets smaller scale
	// AttachedFlattenScale = 0.3 means 30% of original height
	Scale3 = clamp(AttachedFlattenScale * AnisotropyScale, AnisotropyMin, AnisotropyMax);

	// Perpendicular directions get stretched to compensate (volume preservation)
	// AttachedStretchScale = 1.5 means 150% in perpendicular directions
	Scale1 = clamp(AttachedStretchScale * AnisotropyScale, AnisotropyMin, AnisotropyMax);
	Scale2 = Scale1;

	// Volume preservation: Scale1 * Scale2 * Scale3 = 1.0
	float Volume = Scale1 * Scale2 * Scale3;
	if (Volume > 0.001f && abs(Volume - 1.0f) > 0.001f)
	{
		float VolumeNorm = pow(Volume, 1.0f / 3.0f);
		Scale1 /= VolumeNorm;
		Scale2 /= VolumeNorm;
		Scale3 /= VolumeNorm;
	}
}
*/

//-----------------------------------------------------------------------------
// Main Compute Shader
//-----------------------------------------------------------------------------
[numthreads(THREADGROUP_SIZE, 1, 1)]
void MainCS(uint3 DispatchThreadId : SV_DispatchThreadID)
{
	uint Idx = DispatchThreadId.x;
	if (Idx >= ParticleCount)
	{
		return;
	}

	float3 Axis1, Axis2, Axis3;
	float Scale1, Scale2, Scale3;
	int NeighborCount = 0;

	// Read particle data (SOA)
	uint idx3 = Idx * 3;
	uint flags = InFlags[Idx];
	float3 velocity = float3(InVelocities[idx3], InVelocities[idx3 + 1], InVelocities[idx3 + 2]);
	bool bIsAttached = (flags & FLAG_IS_ATTACHED) != 0;

	// Get effective velocity for anisotropy calculation
	// For attached particles: use velocity relative to bone (excludes player movement)
	// For detached particles: use actual particle velocity
	float3 EffectiveVelocity = velocity;
	if (bIsAttached)
	{
		FGPUParticleAttachment Attachment = InAttachments[Idx];
		EffectiveVelocity = Attachment.RelativeVelocity;
	}

	// Select anisotropy calculation based on mode
	if (AnisotropyMode == MODE_VELOCITY_BASED)
	{
		// Pure velocity-based: axes from velocity direction
		CalculateVelocityBasedWithVelocity(EffectiveVelocity, Axis1, Axis2, Axis3, Scale1, Scale2, Scale3);
	}
	else if (AnisotropyMode == MODE_DENSITY_BASED)
	{
		// Pure density-based: axes from covariance only
		CalculateDensityBased(Idx, Axis1, Axis2, Axis3, Scale1, Scale2, Scale3, NeighborCount);
	}
	else // MODE_HYBRID
	{
		// Hybrid: density axes + velocity stretching (use effective velocity)
		// Both operations in log space for volume preservation
		CalculateDensityBased(Idx, Axis1, Axis2, Axis3, Scale1, Scale2, Scale3, NeighborCount);

		// Apply velocity stretching in log space
		float Speed = length(EffectiveVelocity);
		if (Speed > 0.001f)
		{
			float3 VelDir = EffectiveVelocity / Speed;

			// Convert current scales to log space
			float LogScale1 = log(max(Scale1, 0.001f));
			float LogScale2 = log(max(Scale2, 0.001f));
			float LogScale3 = log(max(Scale3, 0.001f));

			// Calculate velocity stretch in log space
			float VelStretchFactor = Speed * VelocityStretchFactor * AnisotropyScale;
			float LogVelStretch = log(max(1.0f + VelStretchFactor, 0.001f));

			// Project velocity onto each axis and add stretch in log space
			float Proj1 = abs(dot(VelDir, Axis1));
			float Proj2 = abs(dot(VelDir, Axis2));
			float Proj3 = abs(dot(VelDir, Axis3));
			LogScale1 += LogVelStretch * Proj1;
			LogScale2 += LogVelStretch * Proj2;
			LogScale3 += LogVelStretch * Proj3;

			// Clamp in log space
			float LogMin = log(max(AnisotropyMin, 0.001f));
			float LogMax = log(max(AnisotropyMax, 0.001f));
			LogScale1 = clamp(LogScale1, LogMin, LogMax);
			LogScale2 = clamp(LogScale2, LogMin, LogMax);
			LogScale3 = clamp(LogScale3, LogMin, LogMax);

			// Re-center logs to maintain volume = 1.0
			float LogSum = LogScale1 + LogScale2 + LogScale3;
			float LogAvg = LogSum / 3.0f;
			LogScale1 -= LogAvg;
			LogScale2 -= LogAvg;
			LogScale3 -= LogAvg;

			// Convert back to linear space
			Scale1 = exp(LogScale1);
			Scale2 = exp(LogScale2);
			Scale3 = exp(LogScale3);
		}
	}

	// =========================================================================
	// Temporal Smoothing: Blend with previous frame (NVIDIA FleX style)
	// - Handle eigenvector sign ambiguity (v and -v are both valid)
	// - Blend scales in log space for volume preservation
	// =========================================================================
	if (bEnableTemporalSmoothing && bHasPreviousFrame)
	{
		float4 Prev1 = PrevAnisotropyAxis1[Idx];
		float4 Prev2 = PrevAnisotropyAxis2[Idx];
		float4 Prev3 = PrevAnisotropyAxis3[Idx];

		// Handle eigenvector sign ambiguity (flip if pointing opposite direction)
		if (dot(Axis1, Prev1.xyz) < 0.0f) Axis1 = -Axis1;
		if (dot(Axis2, Prev2.xyz) < 0.0f) Axis2 = -Axis2;
		if (dot(Axis3, Prev3.xyz) < 0.0f) Axis3 = -Axis3;

		// Blend axes (normalized lerp)
		Axis1 = normalize(lerp(Axis1, Prev1.xyz, TemporalSmoothFactor));
		Axis2 = normalize(lerp(Axis2, Prev2.xyz, TemporalSmoothFactor));
		Axis3 = normalize(lerp(Axis3, Prev3.xyz, TemporalSmoothFactor));

		// Blend scales in log space (volume preservation)
		float LogScale1 = lerp(log(max(Scale1, 0.001f)), log(max(Prev1.w, 0.001f)), TemporalSmoothFactor);
		float LogScale2 = lerp(log(max(Scale2, 0.001f)), log(max(Prev2.w, 0.001f)), TemporalSmoothFactor);
		float LogScale3 = lerp(log(max(Scale3, 0.001f)), log(max(Prev3.w, 0.001f)), TemporalSmoothFactor);
		Scale1 = exp(LogScale1);
		Scale2 = exp(LogScale2);
		Scale3 = exp(LogScale3);
	}

	// Write output (direction.xyz + scale.w)
	OutAnisotropyAxis1[Idx] = float4(Axis1, Scale1);
	OutAnisotropyAxis2[Idx] = float4(Axis2, Scale2);
	OutAnisotropyAxis3[Idx] = float4(Axis3, Scale3);
}
