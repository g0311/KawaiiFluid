// Copyright KawaiiFluid Team. All Rights Reserved.

#include "/Engine/Private/Common.ush"
#include "FluidSpatialHash.ush"
#include "FluidMortonUtils.ush"

//-----------------------------------------------------------------------------
// Anisotropy Compute Shader
// Calculates ellipsoid orientation and scale for each particle
// Based on NVIDIA FleX and Yu & Turk 2013
//-----------------------------------------------------------------------------

// GPU Fluid Particle Structure (must match FGPUFluidParticle in C++)
struct FGPUFluidParticle
{
	float3 Position;           // 12 bytes
	float Mass;                // 4 bytes

	float3 PredictedPosition;  // 12 bytes
	float Density;             // 4 bytes

	float3 Velocity;           // 12 bytes
	float Lambda;              // 4 bytes

	int ParticleID;            // 4 bytes
	int SourceID;              // 4 bytes - Source identification (PresetIndex | ComponentIndex << 16)
	uint Flags;                // 4 bytes
	uint NeighborCount;        // 4 bytes
};

// GPU Particle Attachment Structure (must match FGPUParticleAttachment in C++)
struct FGPUParticleAttachment
{
	int PrimitiveType;         // 4 bytes
	int PrimitiveIndex;        // 4 bytes
	int BoneIndex;             // 4 bytes
	float AdhesionStrength;    // 4 bytes
	float3 LocalOffset;        // 12 bytes
	float AttachmentTime;      // 4 bytes
	float3 RelativeVelocity;   // 12 bytes - Velocity relative to bone
	float Padding;             // 4 bytes
};

// Particle Flags (must match EGPUParticleFlags in C++)
#define FLAG_IS_ATTACHED (1 << 0)
#define FLAG_IS_SURFACE (1 << 1)
#define FLAG_IS_CORE (1 << 2)
#define FLAG_JUST_DETACHED (1 << 3)

// Anisotropy Mode
#define MODE_VELOCITY_BASED 0
#define MODE_DENSITY_BASED 1
#define MODE_HYBRID 2

// Input: GPU Particle buffer (from simulation)
StructuredBuffer<FGPUFluidParticle> InPhysicsParticles;

// Input: Attachment buffer (for surface normal of attached particles)
StructuredBuffer<FGPUParticleAttachment> InAttachments;

// Spatial Hash buffers (for DensityBased mode)
// TODO(KHJ): Remove legacy hash-based lookup - bUseZOrderSorting is always true
// Legacy hash-based lookup (random access pattern)
StructuredBuffer<uint> CellCounts;
StructuredBuffer<uint> ParticleIndices;

// Morton-sorted lookup (sequential access pattern, cache-friendly)
// When bUseZOrderSorting=1, ParticleBuffer is already sorted by Morton code
// CellStart/CellEnd give contiguous ranges in the sorted buffer
StructuredBuffer<uint> CellStart;           // CellStart[cellID] = first particle index in sorted array
StructuredBuffer<uint> CellEnd;             // CellEnd[cellID] = last particle index in sorted array

// Output: Anisotropy SoA buffers (float4 = direction.xyz + scale.w)
RWStructuredBuffer<float4> OutAnisotropyAxis1;
RWStructuredBuffer<float4> OutAnisotropyAxis2;
RWStructuredBuffer<float4> OutAnisotropyAxis3;

// Parameters
uint ParticleCount;
uint AnisotropyMode;  // 0=Velocity, 1=Density, 2=Hybrid
float VelocityStretchFactor;
float AnisotropyScale;
float AnisotropyMin;
float AnisotropyMax;
float DensityWeight;  // For Hybrid mode
float SmoothingRadius;
float CellSize;
// TODO(KHJ): Remove bUseZOrderSorting - always true, legacy path is dead code
int bUseZOrderSorting;  // 1 = use Morton-sorted CellStart/End, 0 = use legacy CellCounts

// Attached particle anisotropy params
float AttachedFlattenScale;   // How flat (0.3 = 30% height along normal)
float AttachedStretchScale;   // Perpendicular stretch (1.5 = 150%)

// Morton code parameters (for Z-Order sorting mode)
float3 MortonBoundsMin;       // Grid origin for Morton code calculation

//-----------------------------------------------------------------------------
// FleX / Yu & Turk Style Constants
//-----------------------------------------------------------------------------

// Eigenvalue ratio clamping (prevents too-thin ellipsoids)
// kr = 10 means minimum scale is 10% of maximum (very flat pancakes)
#define K_R 10.0f

// Minimum neighbors for covariance calculation (PCA requires at least 4)
#define MIN_NEIGHBORS_FOR_ANISOTROPY 4

// Neighbor count for full anisotropy (surface particles typically have ~6+)
// At MIN(4): sphere, At FULL(6): complete anisotropy
#define FULL_NEIGHBORS_FOR_ANISOTROPY 6

// Stretch multiplier to make ellipsoids visually elongated
// FleX uses 1.0 (no extra multiplier) - higher values cause edge artifacts
#define STRETCH_MULTIPLIER 1.0f

//-----------------------------------------------------------------------------
// Helper: Build orthonormal basis from direction (Frisvad's method)
//-----------------------------------------------------------------------------
void BuildOrthonormalBasis(float3 N, out float3 T, out float3 B)
{
	if (N.z < -0.9999999f)
	{
		T = float3(0.0f, -1.0f, 0.0f);
		B = float3(-1.0f, 0.0f, 0.0f);
	}
	else
	{
		float A = 1.0f / (1.0f + N.z);
		float D = -N.x * N.y * A;
		T = float3(1.0f - N.x * N.x * A, D, -N.x);
		B = float3(D, 1.0f - N.y * N.y * A, -N.y);
	}
}

//-----------------------------------------------------------------------------
// Helper: SPH Kernel weight (cubic spline)
//-----------------------------------------------------------------------------
float KernelWeight(float Distance, float H)
{
	if (Distance >= H)
	{
		return 0.0f;
	}

	float Q = Distance / H;
	if (Q < 0.5f)
	{
		return 1.0f - 6.0f * Q * Q + 6.0f * Q * Q * Q;
	}
	else
	{
		float OneMinusQ = 1.0f - Q;
		return 2.0f * OneMinusQ * OneMinusQ * OneMinusQ;
	}
}

//-----------------------------------------------------------------------------
// Helper: 3x3 Symmetric Eigenvalue Decomposition (Analytical - Cardano's formula)
// OPTIMIZED: No iteration, direct analytical solution
// Reference: "Eigenvalues of a 3x3 symmetric matrix" - Kopp (2008)
//-----------------------------------------------------------------------------

// Compute eigenvector for a given eigenvalue using cross product method
float3 ComputeEigenvector(float3x3 A, float eigenvalue)
{
	// (A - λI) should have rank 2, so we find null space
	float3 row0 = float3(A[0][0] - eigenvalue, A[0][1], A[0][2]);
	float3 row1 = float3(A[1][0], A[1][1] - eigenvalue, A[1][2]);
	float3 row2 = float3(A[2][0], A[2][1], A[2][2] - eigenvalue);

	// Cross product of two rows gives eigenvector (perpendicular to both)
	float3 cross01 = cross(row0, row1);
	float3 cross12 = cross(row1, row2);
	float3 cross02 = cross(row0, row2);

	// Pick the cross product with largest magnitude for numerical stability
	float len01 = dot(cross01, cross01);
	float len12 = dot(cross12, cross12);
	float len02 = dot(cross02, cross02);

	float3 eigenvec;
	if (len01 >= len12 && len01 >= len02)
	{
		eigenvec = cross01;
	}
	else if (len12 >= len01 && len12 >= len02)
	{
		eigenvec = cross12;
	}
	else
	{
		eigenvec = cross02;
	}

	float len = length(eigenvec);
	if (len > 1e-10f)
	{
		return eigenvec / len;
	}

	// Fallback for degenerate case
	return float3(1, 0, 0);
}

void SymmetricEigen3x3(
	float3x3 M,
	out float3 EigenValues,
	out float3 EigenVec0,
	out float3 EigenVec1,
	out float3 EigenVec2)
{
	// Diagonal and off-diagonal elements
	float m00 = M[0][0], m11 = M[1][1], m22 = M[2][2];
	float m01 = M[0][1], m02 = M[0][2], m12 = M[1][2];

	// Check if already diagonal (common case for sparse distributions)
	float offDiagSq = m01*m01 + m02*m02 + m12*m12;
	if (offDiagSq < 1e-12f)
	{
		// Already diagonal - eigenvalues are diagonal elements
		// Sort descending
		if (m00 >= m11 && m00 >= m22)
		{
			EigenValues.x = m00;
			EigenVec0 = float3(1, 0, 0);
			if (m11 >= m22)
			{
				EigenValues.y = m11;
				EigenValues.z = m22;
				EigenVec1 = float3(0, 1, 0);
				EigenVec2 = float3(0, 0, 1);
			}
			else
			{
				EigenValues.y = m22;
				EigenValues.z = m11;
				EigenVec1 = float3(0, 0, 1);
				EigenVec2 = float3(0, 1, 0);
			}
		}
		else if (m11 >= m00 && m11 >= m22)
		{
			EigenValues.x = m11;
			EigenVec0 = float3(0, 1, 0);
			if (m00 >= m22)
			{
				EigenValues.y = m00;
				EigenValues.z = m22;
				EigenVec1 = float3(1, 0, 0);
				EigenVec2 = float3(0, 0, 1);
			}
			else
			{
				EigenValues.y = m22;
				EigenValues.z = m00;
				EigenVec1 = float3(0, 0, 1);
				EigenVec2 = float3(1, 0, 0);
			}
		}
		else
		{
			EigenValues.x = m22;
			EigenVec0 = float3(0, 0, 1);
			if (m00 >= m11)
			{
				EigenValues.y = m00;
				EigenValues.z = m11;
				EigenVec1 = float3(1, 0, 0);
				EigenVec2 = float3(0, 1, 0);
			}
			else
			{
				EigenValues.y = m11;
				EigenValues.z = m00;
				EigenVec1 = float3(0, 1, 0);
				EigenVec2 = float3(1, 0, 0);
			}
		}
		return;
	}

	// =========================================================================
	// Cardano's formula for eigenvalues of 3x3 symmetric matrix
	// Characteristic polynomial: λ³ - c2*λ² + c1*λ - c0 = 0
	// =========================================================================

	// Invariants of the matrix
	float trace = m00 + m11 + m22;
	float q = trace / 3.0f;

	// Shift matrix by q to make it traceless: B = A - q*I
	float b00 = m00 - q;
	float b11 = m11 - q;
	float b22 = m22 - q;

	// p² = (1/6) * (sum of squares of B elements) * 2
	// For symmetric: p² = (1/6) * (b00² + b11² + b22² + 2*(m01² + m02² + m12²))
	float p2 = (b00*b00 + b11*b11 + b22*b22 + 2.0f * offDiagSq) / 6.0f;

	if (p2 < 1e-12f)
	{
		// Matrix is q*I (all eigenvalues equal)
		EigenValues = float3(q, q, q);
		EigenVec0 = float3(1, 0, 0);
		EigenVec1 = float3(0, 1, 0);
		EigenVec2 = float3(0, 0, 1);
		return;
	}

	float p = sqrt(p2);

	// Determinant of B/p (scaled shifted matrix)
	// det(B) = b00*(b11*b22 - m12²) - m01*(m01*b22 - m12*m02) + m02*(m01*m12 - b11*m02)
	float detB = b00 * (b11*b22 - m12*m12)
	           - m01 * (m01*b22 - m12*m02)
	           + m02 * (m01*m12 - b11*m02);

	// r = det(B/p) / 2 = det(B) / (2 * p³)
	float r = detB / (2.0f * p * p * p);

	// Clamp r to [-1, 1] for numerical stability
	r = clamp(r, -1.0f, 1.0f);

	// Angle for Cardano's formula
	float phi = acos(r) / 3.0f;

	// Three eigenvalues (sorted descending)
	// λk = q + 2*p*cos(φ + 2πk/3) for k = 0, 1, 2
	const float TWO_PI_OVER_3 = 2.0943951f;  // 2π/3

	float lambda0 = q + 2.0f * p * cos(phi);
	float lambda2 = q + 2.0f * p * cos(phi + TWO_PI_OVER_3);
	float lambda1 = 3.0f * q - lambda0 - lambda2;  // trace = sum of eigenvalues

	// Eigenvalues are already sorted: lambda0 >= lambda1 >= lambda2
	EigenValues = float3(lambda0, lambda1, lambda2);

	// =========================================================================
	// Compute eigenvectors using cross product method
	// =========================================================================
	EigenVec0 = ComputeEigenvector(M, lambda0);

	// For second eigenvector, ensure orthogonality to first
	EigenVec1 = ComputeEigenvector(M, lambda1);
	// Gram-Schmidt orthogonalization
	EigenVec1 = EigenVec1 - dot(EigenVec1, EigenVec0) * EigenVec0;
	float len1 = length(EigenVec1);
	if (len1 > 1e-10f)
	{
		EigenVec1 /= len1;
	}
	else
	{
		// Degenerate: build orthogonal vector
		BuildOrthonormalBasis(EigenVec0, EigenVec1, EigenVec2);
		return;
	}

	// Third eigenvector is cross product of first two (guaranteed orthogonal)
	EigenVec2 = cross(EigenVec0, EigenVec1);
}

//-----------------------------------------------------------------------------
// Velocity-Based Anisotropy (with explicit velocity parameter)
// Volume-preserving using log-space processing
//-----------------------------------------------------------------------------
void CalculateVelocityBasedWithVelocity(
	float3 Velocity,
	out float3 Axis1, out float3 Axis2, out float3 Axis3,
	out float Scale1, out float Scale2, out float Scale3)
{
	// Default: identity (sphere)
	Axis1 = float3(1, 0, 0);
	Axis2 = float3(0, 1, 0);
	Axis3 = float3(0, 0, 1);
	Scale1 = Scale2 = Scale3 = 1.0f;

	float Speed = length(Velocity);

	if (Speed > 0.001f)
	{
		Axis1 = Velocity / Speed;
		BuildOrthonormalBasis(Axis1, Axis2, Axis3);

		// Calculate stretch in log space for volume preservation
		// Stretch along velocity: LogScale1 = log(1 + Speed * Stretch)
		// Perpendicular compression: LogScale2 = LogScale3 = -LogScale1 / 2 (volume = 1.0)
		float Stretch = VelocityStretchFactor * AnisotropyScale;
		float RawScale1 = 1.0f + Speed * Stretch;

		// Convert to log space
		float LogScale1 = log(max(RawScale1, 0.001f));
		// Volume preservation: LogScale1 + 2*LogScale2 = 0 => LogScale2 = -LogScale1/2
		float LogScale2 = -LogScale1 * 0.5f;
		float LogScale3 = LogScale2;

		// Clamp in log space
		float LogMin = log(max(AnisotropyMin, 0.001f));
		float LogMax = log(max(AnisotropyMax, 0.001f));
		LogScale1 = clamp(LogScale1, LogMin, LogMax);
		LogScale2 = clamp(LogScale2, LogMin, LogMax);
		LogScale3 = clamp(LogScale3, LogMin, LogMax);

		// Re-center logs to maintain volume = 1.0
		float LogSum = LogScale1 + LogScale2 + LogScale3;
		float LogAvg = LogSum / 3.0f;
		LogScale1 -= LogAvg;
		LogScale2 -= LogAvg;
		LogScale3 -= LogAvg;

		// Convert back to linear space
		Scale1 = exp(LogScale1);
		Scale2 = exp(LogScale2);
		Scale3 = exp(LogScale3);
	}
}

// Wrapper for backward compatibility
void CalculateVelocityBased(
	uint ParticleIndex,
	out float3 Axis1, out float3 Axis2, out float3 Axis3,
	out float Scale1, out float Scale2, out float Scale3)
{
	FGPUFluidParticle P = InPhysicsParticles[ParticleIndex];
	CalculateVelocityBasedWithVelocity(P.Velocity, Axis1, Axis2, Axis3, Scale1, Scale2, Scale3);
}

//-----------------------------------------------------------------------------
// Density-Based Anisotropy (Covariance Matrix)
// Yu & Turk 2013: "Reconstructing Surfaces of Particle-Based Fluids"
// OPTIMIZED: Single-pass using parallel variance formula
// Cov = E[X*X^T] - E[X]*E[X]^T
//-----------------------------------------------------------------------------
void CalculateDensityBased(
	uint ParticleIndex,
	out float3 Axis1, out float3 Axis2, out float3 Axis3,
	out float Scale1, out float Scale2, out float Scale3,
	out int OutNeighborCount)
{
	// Default: identity (sphere with scale 1.0, NOT AnisotropyScale)
	// AnisotropyScale is intensity parameter, not base size
	Axis1 = float3(1, 0, 0);
	Axis2 = float3(0, 1, 0);
	Axis3 = float3(0, 0, 1);
	Scale1 = Scale2 = Scale3 = 1.0f;
	OutNeighborCount = 0;

	FGPUFluidParticle P = InPhysicsParticles[ParticleIndex];
	float3 CenterPos = P.Position;

	int3 CenterCell = WorldToCell(CenterPos, CellSize);
	int CellRadius = (int)ceil(SmoothingRadius / CellSize);
	float H2 = SmoothingRadius * SmoothingRadius;

	// =========================================================================
	// Single Pass: Collect all statistics at once
	// Using parallel variance formula: Var(X) = E[X²] - E[X]²
	// Cov = Σ(wi*xi*xi^T)/Σwi - (Σwi*xi/Σwi)(Σwi*xi/Σwi)^T
	// =========================================================================
	float3 SumWX = float3(0, 0, 0);      // Σ(wi * xi)
	float SumWXX_00 = 0, SumWXX_01 = 0, SumWXX_02 = 0;  // Σ(wi * xi * xi^T)
	float SumWXX_11 = 0, SumWXX_12 = 0, SumWXX_22 = 0;  // (symmetric, only upper triangle)
	float TotalWeight = 0.0f;            // Σwi
	int NeighborCount = 0;

	// =========================================================================
	// Neighbor Traversal: Two modes for different memory access patterns
	// =========================================================================
	if (bUseZOrderSorting)
	{
		// =====================================================================
		// Z-Order (Morton) Mode: Sequential memory access via CellStart/End
		// Particles are sorted by Morton code, so neighbors are contiguous
		// This enables better cache utilization and coalesced memory reads
		// =====================================================================
		for (int dz = -CellRadius; dz <= CellRadius; ++dz)
		{
			for (int dy = -CellRadius; dy <= CellRadius; ++dy)
			{
				for (int dx = -CellRadius; dx <= CellRadius; ++dx)
				{
					int3 NeighborCell = CenterCell + int3(dx, dy, dz);
					uint CellID = GetMortonCellIDFromCellCoord(NeighborCell, MortonBoundsMin, CellSize);
					uint Start = CellStart[CellID];
					uint End = CellEnd[CellID];

					// Skip empty cells
					if (Start == INVALID_INDEX || End == INVALID_INDEX)
					{
						continue;
					}

					// Clamp end to valid range
					End = min(End, (uint)(ParticleCount - 1));

					// Sequential access through sorted particle range
					// ParticleBuffer is already sorted by Morton code, so we access directly
					for (uint NeighborIdx = Start; NeighborIdx <= End; ++NeighborIdx)
					{
						if (NeighborIdx >= ParticleCount)
						{
							continue;
						}

						float3 NeighborPos = InPhysicsParticles[NeighborIdx].Position;
						float3 Diff = NeighborPos - CenterPos;
						float Dist2 = dot(Diff, Diff);

						if (Dist2 < H2)
						{
							float Dist = sqrt(Dist2);
							float W = KernelWeight(Dist, SmoothingRadius);

							if (W > 0.0001f)
							{
								SumWX += W * NeighborPos;
								TotalWeight += W;
								NeighborCount++;

								SumWXX_00 += W * NeighborPos.x * NeighborPos.x;
								SumWXX_01 += W * NeighborPos.x * NeighborPos.y;
								SumWXX_02 += W * NeighborPos.x * NeighborPos.z;
								SumWXX_11 += W * NeighborPos.y * NeighborPos.y;
								SumWXX_12 += W * NeighborPos.y * NeighborPos.z;
								SumWXX_22 += W * NeighborPos.z * NeighborPos.z;
							}
						}
					}
				}
			}
		}
	}
	// TODO(KHJ): Remove entire else block - legacy path is dead code (bUseZOrderSorting always true)
	else
	{
		// =====================================================================
		// Legacy Hash Mode: Random access via CellCounts/ParticleIndices
		// =====================================================================
		for (int dz = -CellRadius; dz <= CellRadius; ++dz)
		{
			for (int dy = -CellRadius; dy <= CellRadius; ++dy)
			{
				for (int dx = -CellRadius; dx <= CellRadius; ++dx)
				{
					int3 NeighborCell = CenterCell + int3(dx, dy, dz);
					uint Hash = HashCell(NeighborCell);
					uint Count = min(CellCounts[Hash], (uint)MAX_PARTICLES_PER_CELL);
					uint BaseIdx = Hash * MAX_PARTICLES_PER_CELL;

					for (uint i = 0; i < Count; ++i)
					{
						uint NeighborIdx = ParticleIndices[BaseIdx + i];
						if (NeighborIdx >= ParticleCount)
						{
							continue;
						}

						float3 NeighborPos = InPhysicsParticles[NeighborIdx].Position;
						float3 Diff = NeighborPos - CenterPos;
						float Dist2 = dot(Diff, Diff);

						if (Dist2 < H2)
						{
							float Dist = sqrt(Dist2);
							float W = KernelWeight(Dist, SmoothingRadius);

							if (W > 0.0001f)
							{
								SumWX += W * NeighborPos;
								TotalWeight += W;
								NeighborCount++;

								SumWXX_00 += W * NeighborPos.x * NeighborPos.x;
								SumWXX_01 += W * NeighborPos.x * NeighborPos.y;
								SumWXX_02 += W * NeighborPos.x * NeighborPos.z;
								SumWXX_11 += W * NeighborPos.y * NeighborPos.y;
								SumWXX_12 += W * NeighborPos.y * NeighborPos.z;
								SumWXX_22 += W * NeighborPos.z * NeighborPos.z;
							}
						}
					}
				}
			}
		}
	}

	OutNeighborCount = NeighborCount;

	// Need minimum neighbors for reliable covariance
	if (NeighborCount < MIN_NEIGHBORS_FOR_ANISOTROPY || TotalWeight < 0.0001f)
	{
		return;
	}

	// =========================================================================
	// Post-calculation: Derive mean and covariance from accumulated values
	// =========================================================================
	float InvW = 1.0f / TotalWeight;

	// Weighted mean: E[X] = Σ(wi*xi) / Σwi
	float3 WeightedMean = SumWX * InvW;

	// E[X*X^T] = Σ(wi*xi*xi^T) / Σwi
	float EXX_00 = SumWXX_00 * InvW;
	float EXX_01 = SumWXX_01 * InvW;
	float EXX_02 = SumWXX_02 * InvW;
	float EXX_11 = SumWXX_11 * InvW;
	float EXX_12 = SumWXX_12 * InvW;
	float EXX_22 = SumWXX_22 * InvW;

	// E[X]*E[X]^T (outer product of mean with itself)
	float MeanOuter_00 = WeightedMean.x * WeightedMean.x;
	float MeanOuter_01 = WeightedMean.x * WeightedMean.y;
	float MeanOuter_02 = WeightedMean.x * WeightedMean.z;
	float MeanOuter_11 = WeightedMean.y * WeightedMean.y;
	float MeanOuter_12 = WeightedMean.y * WeightedMean.z;
	float MeanOuter_22 = WeightedMean.z * WeightedMean.z;

	// Covariance = E[X*X^T] - E[X]*E[X]^T
	float3x3 CovMatrix;
	CovMatrix[0][0] = EXX_00 - MeanOuter_00;
	CovMatrix[0][1] = EXX_01 - MeanOuter_01;
	CovMatrix[0][2] = EXX_02 - MeanOuter_02;
	CovMatrix[1][0] = CovMatrix[0][1];  // Symmetric
	CovMatrix[1][1] = EXX_11 - MeanOuter_11;
	CovMatrix[1][2] = EXX_12 - MeanOuter_12;
	CovMatrix[2][0] = CovMatrix[0][2];  // Symmetric
	CovMatrix[2][1] = CovMatrix[1][2];  // Symmetric
	CovMatrix[2][2] = EXX_22 - MeanOuter_22;

	// Eigenvalue decomposition
	float3 EigenValues;
	float3 EV0, EV1, EV2;
	SymmetricEigen3x3(CovMatrix, EigenValues, EV0, EV1, EV2);

	// Convert to standard deviations
	float Sigma0 = sqrt(max(EigenValues.x, 0.0001f));
	float Sigma1 = sqrt(max(EigenValues.y, 0.0001f));
	float Sigma2 = sqrt(max(EigenValues.z, 0.0001f));

	// Yu & Turk eigenvalue ratio clamping (prevent too thin ellipsoids)
	float MinSigma = Sigma0 / K_R;
	Sigma1 = max(Sigma1, MinSigma);
	Sigma2 = max(Sigma2, MinSigma);

	// =========================================================================
	// Yu & Turk Volume-Preserving Scale Calculation
	// Use geometric mean normalization: Scale1 * Scale2 * Scale3 = 1.0
	// =========================================================================
	float GeoMean = pow(Sigma0 * Sigma1 * Sigma2, 1.0f / 3.0f);

	// Prevent division by zero
	if (GeoMean < 0.0001f)
	{
		GeoMean = 1.0f;
	}

	// Normalized scales (volume = 1.0 guaranteed)
	float EllipsoidScale1 = Sigma0 / GeoMean;
	float EllipsoidScale2 = Sigma1 / GeoMean;
	float EllipsoidScale3 = Sigma2 / GeoMean;

	// =========================================================================
	// Volume-Preserving Log-Space Processing
	// All operations in log space preserve geometric mean (volume = 1.0)
	// Key insight: log(a) + log(b) + log(c) = 0  <=>  a * b * c = 1.0
	// =========================================================================

	// Step 1: Convert to log space
	float LogScale1 = log(max(EllipsoidScale1, 0.001f));
	float LogScale2 = log(max(EllipsoidScale2, 0.001f));
	float LogScale3 = log(max(EllipsoidScale3, 0.001f));

	// Step 2: Apply AnisotropyScale (amplify/dampen ratios)
	// - AnisotropyScale = 0: sphere (all logs become 0)
	// - AnisotropyScale = 1: original ratios
	// - AnisotropyScale > 1: more extreme anisotropy
	LogScale1 *= AnisotropyScale;
	LogScale2 *= AnisotropyScale;
	LogScale3 *= AnisotropyScale;

	// Step 3: Clamp in log space to prevent extreme shapes
	float LogMin = log(max(AnisotropyMin, 0.001f));
	float LogMax = log(max(AnisotropyMax, 0.001f));
	LogScale1 = clamp(LogScale1, LogMin, LogMax);
	LogScale2 = clamp(LogScale2, LogMin, LogMax);
	LogScale3 = clamp(LogScale3, LogMin, LogMax);

	// Step 4: Re-center logs to maintain volume = 1.0 (sum of logs = 0)
	float LogSum = LogScale1 + LogScale2 + LogScale3;
	float LogAvg = LogSum / 3.0f;
	LogScale1 -= LogAvg;
	LogScale2 -= LogAvg;
	LogScale3 -= LogAvg;

	// Step 5: Neighbor-count based blending
	// Surface particles (fewer neighbors) get partial anisotropy
	// Internal particles (more neighbors) get full anisotropy
	float BlendFactor = saturate(
		(float)(NeighborCount - MIN_NEIGHBORS_FOR_ANISOTROPY) /
		(float)(FULL_NEIGHBORS_FOR_ANISOTROPY - MIN_NEIGHBORS_FOR_ANISOTROPY)
	);
	// Lerp in log space: sphere has log scales of (0, 0, 0)
	LogScale1 *= BlendFactor;
	LogScale2 *= BlendFactor;
	LogScale3 *= BlendFactor;

	// Step 6: Convert back to linear space
	Scale1 = exp(LogScale1);
	Scale2 = exp(LogScale2);
	Scale3 = exp(LogScale3);

	// Eigenvectors as axes
	Axis1 = normalize(EV0);
	Axis2 = normalize(EV1);
	Axis3 = normalize(EV2);
}

//-----------------------------------------------------------------------------
// Apply Velocity Stretching to existing ellipsoid
// Stretches the ellipsoid along velocity direction (Yu & Turk style)
//-----------------------------------------------------------------------------
void ApplyVelocityStretching(
	uint ParticleIndex,
	inout float3 Axis1, inout float3 Axis2, inout float3 Axis3,
	inout float Scale1, inout float Scale2, inout float Scale3)
{
	FGPUFluidParticle P = InPhysicsParticles[ParticleIndex];
	float Speed = length(P.Velocity);

	if (Speed < 0.001f)
	{
		return;
	}

	float3 VelDir = P.Velocity / Speed;

	// Calculate velocity stretch factor
	float VelStretch = 1.0f + Speed * VelocityStretchFactor * AnisotropyScale;
	VelStretch = clamp(VelStretch, 1.0f, AnisotropyMax);

	// Project velocity onto each axis and stretch accordingly
	float Proj1 = abs(dot(VelDir, Axis1));
	float Proj2 = abs(dot(VelDir, Axis2));
	float Proj3 = abs(dot(VelDir, Axis3));

	// Apply stretch proportionally to projection
	Scale1 *= lerp(1.0f, VelStretch, Proj1);
	Scale2 *= lerp(1.0f, VelStretch, Proj2);
	Scale3 *= lerp(1.0f, VelStretch, Proj3);

	// Re-clamp scales
	Scale1 = clamp(Scale1, AnisotropyMin, AnisotropyMax);
	Scale2 = clamp(Scale2, AnisotropyMin, AnisotropyMax);
	Scale3 = clamp(Scale3, AnisotropyMin, AnisotropyMax);

	// Volume preservation after velocity stretching
	float VelVolume = Scale1 * Scale2 * Scale3;
	if (VelVolume > 0.001f && abs(VelVolume - 1.0f) > 0.001f)
	{
		float VelVolumeNorm = pow(VelVolume, 1.0f / 3.0f);
		Scale1 /= VelVolumeNorm;
		Scale2 /= VelVolumeNorm;
		Scale3 /= VelVolumeNorm;
	}
}

//-----------------------------------------------------------------------------
// Attached Particle Anisotropy (DISABLED - SurfaceNormal not in struct)
// TODO: Add SurfaceNormal to FGPUParticleAttachment if needed
//-----------------------------------------------------------------------------
/*
void CalculateAttachedAnisotropy(
	uint ParticleIndex,
	out float3 Axis1, out float3 Axis2, out float3 Axis3,
	out float Scale1, out float Scale2, out float Scale3)
{
	// Default: identity (sphere)
	Axis1 = float3(1, 0, 0);
	Axis2 = float3(0, 1, 0);
	Axis3 = float3(0, 0, 1);
	Scale1 = Scale2 = Scale3 = 1.0f;

	// Read surface normal from attachment data
	FGPUParticleAttachment Attachment = InAttachments[ParticleIndex];
	float3 SurfaceNormal = Attachment.SurfaceNormal;

	// Validate normal
	float NormalLen = length(SurfaceNormal);
	if (NormalLen < 0.001f)
	{
		// Invalid normal, use up vector as fallback
		SurfaceNormal = float3(0, 0, 1);
	}
	else
	{
		SurfaceNormal = SurfaceNormal / NormalLen;
	}

	// Build orthonormal basis with normal as Axis3 (shortest axis)
	// Normal direction = flattened direction (smallest scale)
	Axis3 = SurfaceNormal;
	BuildOrthonormalBasis(Axis3, Axis1, Axis2);

	// Apply flattening: normal direction gets smaller scale
	// AttachedFlattenScale = 0.3 means 30% of original height
	Scale3 = clamp(AttachedFlattenScale * AnisotropyScale, AnisotropyMin, AnisotropyMax);

	// Perpendicular directions get stretched to compensate (volume preservation)
	// AttachedStretchScale = 1.5 means 150% in perpendicular directions
	Scale1 = clamp(AttachedStretchScale * AnisotropyScale, AnisotropyMin, AnisotropyMax);
	Scale2 = Scale1;

	// Volume preservation: Scale1 * Scale2 * Scale3 = 1.0
	float Volume = Scale1 * Scale2 * Scale3;
	if (Volume > 0.001f && abs(Volume - 1.0f) > 0.001f)
	{
		float VolumeNorm = pow(Volume, 1.0f / 3.0f);
		Scale1 /= VolumeNorm;
		Scale2 /= VolumeNorm;
		Scale3 /= VolumeNorm;
	}
}
*/

//-----------------------------------------------------------------------------
// Main Compute Shader
//-----------------------------------------------------------------------------
[numthreads(THREADGROUP_SIZE, 1, 1)]
void MainCS(uint3 DispatchThreadId : SV_DispatchThreadID)
{
	uint Idx = DispatchThreadId.x;
	if (Idx >= ParticleCount)
	{
		return;
	}

	float3 Axis1, Axis2, Axis3;
	float Scale1, Scale2, Scale3;
	int NeighborCount = 0;

	// Read particle data
	FGPUFluidParticle P = InPhysicsParticles[Idx];
	bool bIsAttached = (P.Flags & FLAG_IS_ATTACHED) != 0;

	// Get effective velocity for anisotropy calculation
	// For attached particles: use velocity relative to bone (excludes player movement)
	// For detached particles: use actual particle velocity
	float3 EffectiveVelocity = P.Velocity;
	if (bIsAttached)
	{
		FGPUParticleAttachment Attachment = InAttachments[Idx];
		EffectiveVelocity = Attachment.RelativeVelocity;
	}

	// Select anisotropy calculation based on mode
	if (AnisotropyMode == MODE_VELOCITY_BASED)
	{
		// Pure velocity-based: axes from velocity direction
		CalculateVelocityBasedWithVelocity(EffectiveVelocity, Axis1, Axis2, Axis3, Scale1, Scale2, Scale3);
	}
	else if (AnisotropyMode == MODE_DENSITY_BASED)
	{
		// Pure density-based: axes from covariance only
		CalculateDensityBased(Idx, Axis1, Axis2, Axis3, Scale1, Scale2, Scale3, NeighborCount);
	}
	else // MODE_HYBRID
	{
		// Hybrid: density axes + velocity stretching (use effective velocity)
		// Both operations in log space for volume preservation
		CalculateDensityBased(Idx, Axis1, Axis2, Axis3, Scale1, Scale2, Scale3, NeighborCount);

		// Apply velocity stretching in log space
		float Speed = length(EffectiveVelocity);
		if (Speed > 0.001f)
		{
			float3 VelDir = EffectiveVelocity / Speed;

			// Convert current scales to log space
			float LogScale1 = log(max(Scale1, 0.001f));
			float LogScale2 = log(max(Scale2, 0.001f));
			float LogScale3 = log(max(Scale3, 0.001f));

			// Calculate velocity stretch in log space
			float VelStretchFactor = Speed * VelocityStretchFactor * AnisotropyScale;
			float LogVelStretch = log(max(1.0f + VelStretchFactor, 0.001f));

			// Project velocity onto each axis and add stretch in log space
			float Proj1 = abs(dot(VelDir, Axis1));
			float Proj2 = abs(dot(VelDir, Axis2));
			float Proj3 = abs(dot(VelDir, Axis3));
			LogScale1 += LogVelStretch * Proj1;
			LogScale2 += LogVelStretch * Proj2;
			LogScale3 += LogVelStretch * Proj3;

			// Clamp in log space
			float LogMin = log(max(AnisotropyMin, 0.001f));
			float LogMax = log(max(AnisotropyMax, 0.001f));
			LogScale1 = clamp(LogScale1, LogMin, LogMax);
			LogScale2 = clamp(LogScale2, LogMin, LogMax);
			LogScale3 = clamp(LogScale3, LogMin, LogMax);

			// Re-center logs to maintain volume = 1.0
			float LogSum = LogScale1 + LogScale2 + LogScale3;
			float LogAvg = LogSum / 3.0f;
			LogScale1 -= LogAvg;
			LogScale2 -= LogAvg;
			LogScale3 -= LogAvg;

			// Convert back to linear space
			Scale1 = exp(LogScale1);
			Scale2 = exp(LogScale2);
			Scale3 = exp(LogScale3);
		}
	}

	// Write output (direction.xyz + scale.w)
	OutAnisotropyAxis1[Idx] = float4(Axis1, Scale1);
	OutAnisotropyAxis2[Idx] = float4(Axis2, Scale2);
	OutAnisotropyAxis3[Idx] = float4(Axis3, Scale3);
}
