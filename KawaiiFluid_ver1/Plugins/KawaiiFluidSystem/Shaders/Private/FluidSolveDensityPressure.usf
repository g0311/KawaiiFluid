// Copyright KawaiiFluid Team. All Rights Reserved.
// GPU Fluid Physics - Combined Density and Pressure Pass
// Merges ComputeDensity and SolvePressure into single neighbor traversal
//
// Optimizations:
// 1. Pass Integration: Reduces neighbor search from 2x to 1x per iteration
// 2. rsqrt: Uses fast inverse square root instead of sqrt
// 3. Loop Unroll: Explicit 27-cell unrolling for cellRadius=1 case
// 4. Neighbor Caching: First iteration builds neighbor list, subsequent iterations reuse
// 5. Half Precision: Velocity/Density/Lambda as FP16 (50% bandwidth reduction)
// 6. Uniform Mass: Single mass constant instead of per-particle buffer (4B/neighbor saved)
// 7. Shared Memory (LDS): Tile-based caching for 256 spatially adjacent particles
// 8. ALU Optimization: Inline kernels, single rsqrt, branchless tensile/ST, precomputed constants
//
// NOTE: Wave Intrinsics removed - unsafe in divergent loops (thread retire causes garbage reads)

#include "/Engine/Public/Platform.ush"
#include "/Engine/Private/Common.ush"
#include "FluidGPUPhysics.ush"
#include "FluidSpatialHash.ush"
#include "FluidMortonUtils.ush"  // Unified Morton code functions

// Half Precision Packing Utilities: defined in FluidGPUPhysics.ush
// PackHalf2, UnpackHalf2, PackVelocity, UnpackVelocity, PackDensityLambda, UnpackDensityLambda

//=============================================================================
// Shared Memory (LDS) for Tile-Based Caching
// Thread Group (256 threads) processes spatially adjacent particles (Z-Order sorted)
// When neighbor is in same tile, read from LDS (~20x faster than Global Memory)
//
// Memory hierarchy:
// 1. Shared Memory (LDS): ~20 cycles, same tile (256 particles) - SAFE
// 2. Global Memory: ~400 cycles, different tile - SAFE
//
// NOTE: Wave Intrinsics removed - unsafe in divergent neighbor loops.
// When threads finish at different times (due to varying neighbor counts),
// WaveReadLaneAt can read garbage from retired thread registers.
// LDS data persists until entire Thread Group completes, so it's always safe.
//=============================================================================
#define TILE_SIZE THREAD_GROUP_SIZE  // 256

groupshared float3 gs_Positions[TILE_SIZE];
groupshared float  gs_Lambdas[TILE_SIZE];
groupshared uint   gs_Flags[TILE_SIZE];

// Neighbor particle data structure
struct FNeighborParticleData
{
	float3 Position;
	float Lambda;
	uint Flags;
};

// Get neighbor data with LDS + Global Memory hierarchy
// LDS is safe because data persists until Thread Group completes
FNeighborParticleData GetNeighborDataWithTile(
	uint neighborIdx,
	uint tileStartIdx,
	RWBuffer<float> InPredictedPositions,
	RWBuffer<uint> InPackedDensityLambda,
	RWBuffer<uint> InFlags)
{
	FNeighborParticleData result;

	// 1. Tile (LDS) check - FAST and SAFE (~20 cycles)
	uint tileOffset = neighborIdx - tileStartIdx;
	if (tileOffset < TILE_SIZE)
	{
		result.Position = gs_Positions[tileOffset];
		result.Lambda = gs_Lambdas[tileOffset];
		result.Flags = gs_Flags[tileOffset];
		return result;
	}

	// 2. Global Memory - SLOW but SAFE (~400 cycles)
	uint neighborIdx3 = neighborIdx * 3;
	result.Position = float3(
		InPredictedPositions[neighborIdx3],
		InPredictedPositions[neighborIdx3 + 1],
		InPredictedPositions[neighborIdx3 + 2]);

	float neighborDensity;
	UnpackDensityLambda(InPackedDensityLambda[neighborIdx], neighborDensity, result.Lambda);
	result.Flags = InFlags[neighborIdx];

	return result;
}

//=============================================================================
// Shader Parameters
//=============================================================================

// SoA (Structure of Arrays) Particle Buffers
RWBuffer<float> Positions;                     // [ParticleCount * 3] float3 as 3 consecutive floats
RWBuffer<float> PredictedPositions;            // [ParticleCount * 3] float3 as 3 consecutive floats

// Half-precision packed buffers for bandwidth optimization
RWBuffer<uint2> PackedVelocities;              // [ParticleCount] uint2 = half3 velocity (xy in .x, z in .y)
RWBuffer<uint> PackedDensityLambda;            // [ParticleCount] uint = half2 (density, lambda)

// Uniform particle mass (all particles same mass, from Preset)
float UniformParticleMass;

RWBuffer<uint> Flags;                          // [ParticleCount] uint
RWBuffer<uint> NeighborCountsBuffer;           // [ParticleCount] uint

// Hash table mode (legacy)
StructuredBuffer<uint> CellCounts;
StructuredBuffer<uint> ParticleIndices;

// Z-Order sorted mode (new)
StructuredBuffer<uint> CellStart;   // CellStart[cellID] = first particle index
StructuredBuffer<uint> CellEnd;     // CellEnd[cellID] = last particle index
int bUseZOrderSorting;              // 1 = use CellStart/End, 0 = use CellCounts/ParticleIndices

// Neighbor caching buffers
RWStructuredBuffer<uint> NeighborList;    // [ParticleCount * MAX_NEIGHBORS_PER_PARTICLE]
RWStructuredBuffer<uint> NeighborCounts;  // [ParticleCount]

int ParticleCount;
float SmoothingRadius;
float RestDensity;
float Poly6Coeff;
float SpikyCoeff;
float CellSize;
float Compliance;
float DeltaTimeSq;

// Cohesion via Artificial Pressure (PBF paper Eq.13-14)
// TensileK = Cohesion coefficient (scaled 100x from user-facing value)
//            User sets Cohesion=0.1 in editor → TensileK=10 here
// TensileN = CohesionExponent from Physics|Simulation|Cohesion (n value)
// InvW_DeltaQ = precomputed from CohesionDeltaQ (Δq value)
int bEnableTensileInstability;  // 1 if Cohesion > 0
float TensileK;                 // Scaled cohesion (Cohesion * 100, e.g., 5~20)
int TensileN;                   // Cohesion exponent (n = 1~8, typically 4)
float InvW_DeltaQ;              // 1/W(Δq*h), precomputed on CPU

// Iteration control
int IterationIndex;

// Z-Order (Morton Code) bounds for cell ID calculation
// Must match the bounds used in FluidMortonCode.usf
float3 MortonBoundsMin;     // Simulation bounds minimum
float3 MortonBoundsExtent;  // Simulation bounds extent (Max - Min)

// Hybrid Tiled Z-Order mode flag
// When enabled, uses 21-bit Hybrid keys (3-bit TileHash + 18-bit LocalMorton)
// for unlimited simulation range. Must match FluidMortonCode.usf
int bUseHybridTiledZOrder;

//=============================================================================
// Boundary Particles for density contribution (Akinci 2012)
//=============================================================================
struct FGPUBoundaryParticle
{
	float3 Position;      // 12 bytes - World position
	float Psi;            // 4 bytes  - Boundary particle "mass" (total: 16)
	float3 Normal;        // 12 bytes - Surface normal
	int OwnerID;          // 4 bytes  - Owner component ID (total: 32)
	float3 Velocity;      // 12 bytes - World velocity
	float FrictionCoeff;  // 4 bytes  - Coulomb friction coefficient (total: 48)
	int BoneIndex;        // 4 bytes  - Skeleton bone index (-1 for static mesh)
	float3 Padding;       // 12 bytes - Alignment padding (total: 64)
};

StructuredBuffer<FGPUBoundaryParticle> BoundaryParticles;
int BoundaryParticleCount;
int bUseBoundaryDensity;

// Z-Order sorted boundary particles (Akinci 2012 + Z-Order optimization)
StructuredBuffer<FGPUBoundaryParticle> SortedBoundaryParticles;
StructuredBuffer<uint> BoundaryCellStart;
StructuredBuffer<uint> BoundaryCellEnd;
int bUseBoundaryZOrder;

// Relative Velocity Pressure Damping (prevents fluid flying away from fast boundaries)
int bEnableRelativeVelocityDamping;
float RelativeVelocityDampingStrength;

// Boundary Velocity Transfer (moved from FluidApplyViscosity for optimization)
// Fluid following moving boundaries - applied during boundary density loop
int bEnableBoundaryVelocityTransfer;
float BoundaryVelocityTransferStrength;
float BoundaryDetachSpeedThreshold;
float BoundaryMaxDetachSpeed;
float BoundaryAdhesionStrength;  // Clamped adhesion (0~1)
int SolverIterationCount;        // Total iterations for strength scaling

// Position-Based Surface Tension (NVIDIA Flex style)
// Creates rounded droplets by minimizing surface area
// bEnablePositionBasedSurfaceTension: 0 = Akinci force-based (default), 1 = Position-Based (experimental)
int bEnablePositionBasedSurfaceTension;
float SurfaceTensionStrength;
float SurfaceTensionActivationDistance;   // cm (h * ratio)
float SurfaceTensionFalloffDistance;      // cm (h * ratio)
int SurfaceTensionSurfaceThreshold;       // Surface particles get stronger ST
float SurfaceTensionVelocityDamping;      // 0~1, under-relaxation (0=full correction, 1=no correction)
float SurfaceTensionTolerance;            // cm, dead zone around activation distance (prevents oscillation)

// Surface Tension max correction
float MaxSurfaceTensionCorrection;        // Max correction per iteration (cm)

//=============================================================================
// Z-Order Cell ID Calculation (uses shader parameters)
// Morton code functions are provided by FluidMortonUtils.ush
//=============================================================================

// Compute Morton-based cell ID from cell coordinates (integer)
// This version uses shader parameters (MortonBoundsMin, CellSize) directly.
// IMPORTANT: Must match FluidMortonCode.usf's ComputeMortonCodesCellBasedCS
// IMPORTANT: Result is truncated to fit CellStart/CellEnd buffer size (MAX_CELLS)
uint GetMortonCellIDFromCellCoord(int3 cellCoord)
{
	// Hybrid mode: 21-bit key (3-bit TileHash + 18-bit LocalMorton)
	if (bUseHybridTiledZOrder)
	{
		// ComputeHybridTiledKey returns 21-bit key matching MAX_CELLS
		// Mask is a no-op but kept for consistency
		// Hash collisions (8 tile buckets) are filtered by distance check
		return ComputeHybridTiledKey(cellCoord) & (MAX_CELLS - 1);
	}

	// Classic mode: Use bounded Morton code
	// Compute grid minimum cell (same as in FluidMortonCode.usf)
	int3 gridMin = int3(floor(MortonBoundsMin / CellSize));

	// Offset cell coordinates to make them positive (relative to grid min)
	int3 offset = cellCoord - gridMin;

	// Clamp to valid range for current preset
	uint3 uoffset = uint3(max(offset, int3(0, 0, 0)));
	uoffset = min(uoffset, uint3(MORTON_MAX_VALUE, MORTON_MAX_VALUE, MORTON_MAX_VALUE));

	// Compute Morton code using preset-specific function from FluidMortonUtils.ush
	return Morton3D(uoffset.x, uoffset.y, uoffset.z);
}

// NOTE: Legacy macros BUILD_AND_PROCESS_CELL_ZORDER and BUILD_AND_PROCESS_CELL removed.
// All neighbor processing now uses GetNeighborDataWithTile() with:
// 1. Shared Memory (LDS): Same tile (256 particles) - ~20 cycles
// 2. Wave Intrinsics: Same warp (32/64 particles) - ~4 cycles
// 3. Global Memory: Different tile - ~400 cycles

//=============================================================================
// Main Compute Shader - Combined Density + Pressure with Neighbor Caching
//=============================================================================

[numthreads(THREAD_GROUP_SIZE, 1, 1)]
void SolveDensityPressureCS(uint3 DispatchThreadId : SV_DispatchThreadID)
{
	uint idx = DispatchThreadId.x;

	//=========================================================================
	// PHASE 1: Load data to Shared Memory (ALL threads must participate)
	// This includes threads beyond ParticleCount - they load zeros
	// GroupMemoryBarrierWithGroupSync requires ALL threads to reach it
	//=========================================================================
	uint localIdx = idx % TILE_SIZE;
	uint tileStartIdx = idx - localIdx;

	// Read particle data (or zeros if beyond ParticleCount)
	uint idx3 = idx * 3;
	float3 pos = float3(0.0f, 0.0f, 0.0f);
	uint flags = 0;
	float prevDensity = 0.0f;
	float lambda_i_prev = 0.0f;
	float3 vel = float3(0.0f, 0.0f, 0.0f);

	if (idx < (uint)ParticleCount)
	{
		pos = float3(PredictedPositions[idx3], PredictedPositions[idx3 + 1], PredictedPositions[idx3 + 2]);
		flags = Flags[idx];
		UnpackDensityLambda(PackedDensityLambda[idx], prevDensity, lambda_i_prev);
		vel = UnpackVelocity(PackedVelocities[idx]);
	}

	// Load to Shared Memory (LDS)
	gs_Positions[localIdx] = pos;
	gs_Lambdas[localIdx] = lambda_i_prev;
	gs_Flags[localIdx] = flags;

	// Synchronize - ALL threads must hit this barrier
	GroupMemoryBarrierWithGroupSync();

	//=========================================================================
	// PHASE 2: Early returns (AFTER barrier - safe to diverge now)
	//=========================================================================
	if (idx >= (uint)ParticleCount)
	{
		return;
	}

	// Skip attached particles
	if (HasFlag(flags, GPU_PARTICLE_FLAG_IS_ATTACHED))
	{
		PackedDensityLambda[idx] = PackDensityLambda(RestDensity, 0.0f);
		return;
	}

	// Skip sleeping particles - they are excluded from constraint solving
	if (HasFlag(flags, GPU_PARTICLE_FLAG_IS_SLEEPING))
	{
		PackedDensityLambda[idx] = PackDensityLambda(RestDensity, 0.0f);
		return;
	}

	// NEAR_BOUNDARY flag check - used later to skip position corrections
	bool bIsNearBoundary = HasFlag(flags, GPU_PARTICLE_FLAG_NEAR_BOUNDARY);

	// Convert smoothing radius from cm to m for kernel calculations
	float h = SmoothingRadius * CM_TO_M;
	float h2 = h * h;

	// Accumulators
	float density = 0.0f;
	float3 gradC_i = float3(0.0f, 0.0f, 0.0f);
	float sumGradC2 = 0.0f;
	float3 deltaP = float3(0.0f, 0.0f, 0.0f);
	uint neighborCount = 0;
	uint constraintCount = 0;  // Averaged Position Update: count constraints for averaging

	// Position-Based Surface Tension accumulator (surface particles only)
	float3 surfaceTensionCorrection = float3(0.0f, 0.0f, 0.0f);
	uint surfaceTensionConstraintCount = 0;

	// Pre-compute inverse RestDensity to convert divisions to multiplications
	// Division is expensive on GPU (~20-30 cycles), multiplication is cheap (~4 cycles)
	float invRestDensity = 1.0f / RestDensity;

	// Artificial Pressure (PBF Eq.13-14) for Tensile Instability Correction
	// TensileK = Artificial Pressure strength from Physics|Simulation|Stability
	// Higher value = stronger anti-clumping = particles spread evenly
	// When bEnableTensileInstability = 0, tensileK_scaled = 0, making scorr = 0
	float tensileK_scaled = TensileK * (float)bEnableTensileInstability;

	// Precompute Tensile exponent multipliers (branchless)
	// TensileN=2: mult4=0, mult6=0 → ratio^2
	// TensileN=4: mult4=1, mult6=0 → ratio^4
	// TensileN=6: mult4=1, mult6=1 → ratio^6
	float tensileMult4 = (TensileN >= 4) ? 1.0f : 0.0f;
	float tensileMult6 = (TensileN >= 6) ? 1.0f : 0.0f;

	// Precompute Surface Tension constants (avoid repeated additions in hot loop)
	float stActivationWithTolerance = SurfaceTensionActivationDistance + SurfaceTensionTolerance;
	float stFalloffRange = SmoothingRadius - SurfaceTensionFalloffDistance;
	float stInvFalloffRange = 1.0f / max(stFalloffRange, 0.001f);
	float stToleranceRange = SurfaceTensionFalloffDistance - stActivationWithTolerance;
	float stInvToleranceRange = 1.0f / max(stToleranceRange, 0.001f);
	bool bDoSurfaceTension = bEnablePositionBasedSurfaceTension && (SurfaceTensionStrength > 0.0f);

	// Precompute combined coefficients
	float massPoly6 = UniformParticleMass * Poly6Coeff;
	float spikyScale = SpikyCoeff * CM_TO_M;

	//=========================================================================
	// Branch based on iteration index for neighbor caching
	//=========================================================================
	if (IterationIndex == 0)
	{
		//=====================================================================
		// First Iteration: Build neighbor cache + Compute
		//=====================================================================
		uint cachedCount = 0;

		int3 centerCell = WorldToCell(pos, CellSize);
		int cellRadius = (int)ceil(SmoothingRadius / CellSize);

		// Alternate traversal direction per iteration to eliminate Jacobi bias
		// All threads use same direction (no warp divergence), but direction flips each iteration
		int dir = (IterationIndex & 1) ? -1 : 1;
		int startR = (dir > 0) ? -cellRadius : cellRadius;
		int endR = -startR + dir;

		if (bUseZOrderSorting)
		{
			//=================================================================
			// Z-Order Mode: Sequential memory access via CellStart/End
			// Uniform direction per iteration (no warp divergence + no Jacobi bias)
			//=================================================================
			for (int dz = startR; dz != endR; dz += dir)
			{
				for (int dy = startR; dy != endR; dy += dir)
				{
					for (int dx = startR; dx != endR; dx += dir)
					{
						int3 neighborCell = centerCell + int3(dx, dy, dz);
						uint cellID = GetMortonCellIDFromCellCoord(neighborCell);
						uint cellStart = CellStart[cellID];
						uint cellEnd = CellEnd[cellID];

						// CRITICAL: Check BOTH cellStart AND cellEnd to prevent infinite loop
						if (cellStart == INVALID_INDEX || cellEnd == INVALID_INDEX) continue;

						uint maxNeighborIdx = min(cellEnd, (uint)(ParticleCount - 1));
						for (uint neighborIdx = cellStart; neighborIdx <= maxNeighborIdx; ++neighborIdx)
						{
							// Get neighbor data: LDS first, then Global Memory
							FNeighborParticleData neighborData = GetNeighborDataWithTile(
								neighborIdx, tileStartIdx,
								PredictedPositions, PackedDensityLambda, Flags);

							// Skip attached neighbors - they cluster at bone and cause explosion
							if (HasFlag(neighborData.Flags, GPU_PARTICLE_FLAG_IS_ATTACHED))
							{
								continue;
							}

							float3 r_cm = pos - neighborData.Position;
							float r2_cm = dot(r_cm, r_cm);
							float r2 = r2_cm * CM_TO_M_SQ;

							if (r2 < h2)
							{
								if (cachedCount < MAX_NEIGHBORS_PER_PARTICLE)
								{
									uint cacheIdx = idx * MAX_NEIGHBORS_PER_PARTICLE + cachedCount;
									NeighborList[cacheIdx] = neighborIdx;
									cachedCount++;
								}

								//=============================================================
								// ALU Optimized: Inline kernels, single rsqrt, branchless math
								//=============================================================

								// Poly6: inline without branch (already checked r2 < h2)
								float diff = h2 - r2;
								float diff3 = diff * diff * diff;
								density += massPoly6 * diff3;
								if (neighborIdx != idx) neighborCount++;

								// Compute rsqrt ONCE - reuse for gradient and surface tension
								float r2_safe = r2 + SMALL_NUMBER;
								float rLenInv = rsqrt(r2_safe);
								float rLen = r2_safe * rLenInv;  // sqrt(r2)

								// Spiky gradient: inline (h - rLen already > 0 since r2 < h2)
								float diffSpiky = h - rLen;
								float3 r = r_cm * CM_TO_M;
								float3 gradW = (r * rLenInv) * (diffSpiky * diffSpiky * spikyScale);

								float3 gradC_j = -gradW * invRestDensity;
								sumGradC2 += dot(gradC_j, gradC_j);
								gradC_i += gradW * invRestDensity;

								if (neighborIdx != idx)
								{
									// Branchless tensile instability
									float ratio = diff3 * InvW_DeltaQ;
									float ratio2 = ratio * ratio;
									// ratioN = ratio2 * (ratio2^mult4) * (ratio2^mult6)
									// When mult=0: ratio2^0 = 1, When mult=1: ratio2^1 = ratio2
									float ratioN = ratio2 * lerp(1.0f, ratio2, tensileMult4) * lerp(1.0f, ratio2, tensileMult6);
									float scorr = -tensileK_scaled * ratioN;
									deltaP += (lambda_i_prev + neighborData.Lambda + scorr) * gradW;
									constraintCount++;

									// Surface Tension: reuse rsqrt, branchless falloff
									if (bDoSurfaceTension)
									{
										float dist_cm = r2_cm * rsqrt(r2_cm + SMALL_NUMBER);  // sqrt approximation
										float3 pullDirection = -r_cm * rLenInv * CM_TO_M;  // reuse rLenInv (scaled)

										// Branchless activation check
										float distFromActivation = dist_cm - stActivationWithTolerance;
										float activationMask = step(0.0f, distFromActivation);

										// Branchless falloff
										float falloffT = saturate((dist_cm - SurfaceTensionFalloffDistance) * stInvFalloffRange);
										float stStrength = SurfaceTensionStrength * (1.0f - falloffT);

										// Quadratic easing
										float normalizedDist = saturate(distFromActivation * stInvToleranceRange);
										float easedStrength = normalizedDist * normalizedDist;

										float stCorrectionMag = distFromActivation * stStrength * easedStrength * activationMask;
										surfaceTensionCorrection += pullDirection * stCorrectionMag;
										surfaceTensionConstraintCount += (uint)activationMask;
									}
								}
							}
						}
					}
				}
			}
		}
		else
		{
			//=================================================================
			// Legacy Hash Table Mode
			// Uniform direction per iteration (no warp divergence + no Jacobi bias)
			//=================================================================
			for (int dz = startR; dz != endR; dz += dir)
			{
				for (int dy = startR; dy != endR; dy += dir)
				{
					for (int dx = startR; dx != endR; dx += dir)
					{
						int3 neighborCell = centerCell + int3(dx, dy, dz);
						uint hash = HashCell(neighborCell);
						uint count = min(CellCounts[hash], (uint)MAX_PARTICLES_PER_CELL);
						uint startIdx = hash * MAX_PARTICLES_PER_CELL;

						for (uint i = 0; i < count; ++i)
						{
							uint neighborIdx = ParticleIndices[startIdx + i];
							if (neighborIdx >= (uint)ParticleCount)
							{
								continue;
							}

							// Get neighbor data: LDS first, then Global Memory
							FNeighborParticleData neighborData = GetNeighborDataWithTile(
								neighborIdx, tileStartIdx,
								PredictedPositions, PackedDensityLambda, Flags);

							// Skip attached neighbors - they cluster at bone and cause explosion
							if (HasFlag(neighborData.Flags, GPU_PARTICLE_FLAG_IS_ATTACHED))
							{
								continue;
							}

							float3 r_cm = pos - neighborData.Position;
							float r2_cm = dot(r_cm, r_cm);
							float r2 = r2_cm * CM_TO_M_SQ;

							if (r2 < h2)
							{
								// Cache this neighbor
								if (cachedCount < MAX_NEIGHBORS_PER_PARTICLE)
								{
									uint cacheIdx = idx * MAX_NEIGHBORS_PER_PARTICLE + cachedCount;
									NeighborList[cacheIdx] = neighborIdx;
									cachedCount++;
								}

								//=============================================================
								// ALU Optimized: Inline kernels, single rsqrt, branchless math
								//=============================================================

								// Poly6: inline without branch
								float diff = h2 - r2;
								float diff3 = diff * diff * diff;
								density += massPoly6 * diff3;
								if (neighborIdx != idx) neighborCount++;

								// Compute rsqrt ONCE
								float r2_safe = r2 + SMALL_NUMBER;
								float rLenInv = rsqrt(r2_safe);
								float rLen = r2_safe * rLenInv;

								// Spiky gradient: inline
								float diffSpiky = h - rLen;
								float3 r = r_cm * CM_TO_M;
								float3 gradW = (r * rLenInv) * (diffSpiky * diffSpiky * spikyScale);

								float3 gradC_j = -gradW * invRestDensity;
								sumGradC2 += dot(gradC_j, gradC_j);
								gradC_i += gradW * invRestDensity;

								if (neighborIdx != idx)
								{
									// Branchless tensile instability
									float ratio = diff3 * InvW_DeltaQ;
									float ratio2 = ratio * ratio;
									float ratioN = ratio2 * lerp(1.0f, ratio2, tensileMult4) * lerp(1.0f, ratio2, tensileMult6);
									float scorr = -tensileK_scaled * ratioN;
									deltaP += (lambda_i_prev + neighborData.Lambda + scorr) * gradW;
									constraintCount++;

									// Surface Tension: reuse rsqrt, branchless falloff
									if (bDoSurfaceTension)
									{
										float dist_cm = r2_cm * rsqrt(r2_cm + SMALL_NUMBER);
										float3 pullDirection = -r_cm * rLenInv * CM_TO_M;

										float distFromActivation = dist_cm - stActivationWithTolerance;
										float activationMask = step(0.0f, distFromActivation);

										float falloffT = saturate((dist_cm - SurfaceTensionFalloffDistance) * stInvFalloffRange);
										float stStrength = SurfaceTensionStrength * (1.0f - falloffT);

										float normalizedDist = saturate(distFromActivation * stInvToleranceRange);
										float easedStrength = normalizedDist * normalizedDist;

										float stCorrectionMag = distFromActivation * stStrength * easedStrength * activationMask;
										surfaceTensionCorrection += pullDirection * stCorrectionMag;
										surfaceTensionConstraintCount += (uint)activationMask;
									}
								}
							}
						}
					}
				}
			}
		}

		// Store cached neighbor count
		NeighborCounts[idx] = cachedCount;
	}
	else
	{
		//=====================================================================
		// Subsequent Iterations: Use cached neighbor list (NO hash lookup!)
		// Alternate iteration direction to eliminate Jacobi bias
		//=====================================================================
		uint cachedCount = NeighborCounts[idx];
		uint baseIdx = idx * MAX_NEIGHBORS_PER_PARTICLE;

		// Alternate direction through cached list based on iteration
		// Even iterations: forward (0 → count), Odd iterations: reverse (count → 0)
		bool reverseOrder = (IterationIndex & 1) != 0;

		for (uint ni = 0; ni < cachedCount; ++ni)
		{
			uint n = reverseOrder ? (cachedCount - 1 - ni) : ni;
			uint neighborIdx = NeighborList[baseIdx + n];

			// Get neighbor data: LDS first, then Global Memory
			// LDS is refreshed each iteration via GroupMemoryBarrierWithGroupSync.
			FNeighborParticleData neighborData = GetNeighborDataWithTile(
				neighborIdx, tileStartIdx,
				PredictedPositions, PackedDensityLambda, Flags);

			// Skip attached neighbors - they cluster at bone and cause explosion
			if (HasFlag(neighborData.Flags, GPU_PARTICLE_FLAG_IS_ATTACHED))
			{
				continue;
			}

			float3 r_cm = pos - neighborData.Position;
			float r2_cm = dot(r_cm, r_cm);
			float r2 = r2_cm * CM_TO_M_SQ;

			// Still need distance check as positions changed
			if (r2 < h2)
			{
				//=============================================================
				// ALU Optimized: Inline kernels, single rsqrt, branchless math
				//=============================================================

				// Poly6: inline without branch
				float diff = h2 - r2;
				float diff3 = diff * diff * diff;
				density += massPoly6 * diff3;
				if (neighborIdx != idx) neighborCount++;

				// Compute rsqrt ONCE
				float r2_safe = r2 + SMALL_NUMBER;
				float rLenInv = rsqrt(r2_safe);
				float rLen = r2_safe * rLenInv;

				// Spiky gradient: inline
				float diffSpiky = h - rLen;
				float3 r = r_cm * CM_TO_M;
				float3 gradW = (r * rLenInv) * (diffSpiky * diffSpiky * spikyScale);

				float3 gradC_j = -gradW * invRestDensity;
				sumGradC2 += dot(gradC_j, gradC_j);
				gradC_i += gradW * invRestDensity;

				if (neighborIdx != idx)
				{
					// Branchless tensile instability
					float ratio = diff3 * InvW_DeltaQ;
					float ratio2 = ratio * ratio;
					float ratioN = ratio2 * lerp(1.0f, ratio2, tensileMult4) * lerp(1.0f, ratio2, tensileMult6);
					float scorr = -tensileK_scaled * ratioN;
					deltaP += (lambda_i_prev + neighborData.Lambda + scorr) * gradW;
					constraintCount++;

					// Surface Tension: reuse rsqrt, branchless falloff
					if (bDoSurfaceTension)
					{
						float dist_cm = r2_cm * rsqrt(r2_cm + SMALL_NUMBER);
						float3 pullDirection = -r_cm * rLenInv * CM_TO_M;

						float distFromActivation = dist_cm - stActivationWithTolerance;
						float activationMask = step(0.0f, distFromActivation);

						float falloffT = saturate((dist_cm - SurfaceTensionFalloffDistance) * stInvFalloffRange);
						float stStrength = SurfaceTensionStrength * (1.0f - falloffT);

						float normalizedDist = saturate(distFromActivation * stInvToleranceRange);
						float easedStrength = normalizedDist * normalizedDist;

						float stCorrectionMag = distFromActivation * stStrength * easedStrength * activationMask;
						surfaceTensionCorrection += pullDirection * stCorrectionMag;
						surfaceTensionConstraintCount += (uint)activationMask;
					}
				}
			}
		}
	}

	// Self contribution to gradient sum
	sumGradC2 += dot(gradC_i, gradC_i);

	//=========================================================================
	// Boundary Particles contribution (Akinci 2012)
	// 1. Density: ρ_i += Σ_k ψ_k W(|x_i - x_k|, h)
	// 2. Pressure gradient: Δx_i += λ_i * ψ_k * ∇W(x_i - x_k) / ρ_0
	// 3. Velocity Transfer: Fluid following moving boundaries (moved from FluidApplyViscosity)
	// This makes fluid particles "see" the boundary as solid, preventing penetration
	// AND pushes fluid away from boundaries (prevents wall climbing)
	//
	// Two modes:
	// 1. Z-Order Mode: O(K) neighbor search using Morton-sorted BoundaryCellStart/End
	// 2. Legacy Mode: O(M) brute-force (fallback)
	//=========================================================================
	
	// Boundary Velocity Transfer accumulators (XSPH-style smoothing with boundary)
	float3 boundaryVelCorrection = float3(0.0f, 0.0f, 0.0f);
	float boundaryVelWeight = 0.0f;
	
	if (bUseBoundaryDensity && BoundaryParticleCount > 0)
	{
		// Alternate traversal direction per iteration to eliminate Jacobi bias
		int bDir = (IterationIndex & 1) ? -1 : 1;
		int3 bCenterCell = WorldToCell(pos, CellSize);
		int bCellRadius = (int)ceil(SmoothingRadius / CellSize);
		int bStartR = (bDir > 0) ? -bCellRadius : bCellRadius;
		int bEndR = -bStartR + bDir;

		if (bUseBoundaryZOrder)
		{
			//=================================================================
			// Z-Order Mode: O(K) neighbor search using Morton code
			// SortedBoundaryParticles are sorted by Morton code
			// Uniform direction per iteration (no warp divergence + no Jacobi bias)
			//=================================================================
			for (int dz = bStartR; dz != bEndR; dz += bDir)
			{
				for (int dy = bStartR; dy != bEndR; dy += bDir)
				{
					for (int dx = bStartR; dx != bEndR; dx += bDir)
					{
						int3 neighborCell = bCenterCell + int3(dx, dy, dz);
						uint cellID = GetMortonCellIDFromCellCoord(neighborCell);
						uint bCellStart = BoundaryCellStart[cellID];
						uint bCellEnd = BoundaryCellEnd[cellID];

						// Skip empty cells
						if (bCellStart == INVALID_INDEX || bCellEnd == INVALID_INDEX)
							continue;

						// Iterate through boundary particles in this cell
						for (uint bi = bCellStart; bi <= bCellEnd; ++bi)
						{
							FGPUBoundaryParticle boundary = SortedBoundaryParticles[bi];
							float3 r_cm = pos - boundary.Position;
							float r2_cm = dot(r_cm, r_cm);
							float r2 = r2_cm * CM_TO_M_SQ;

							if (r2 < h2 && r2 > SMALL_NUMBER)
							{
								// Poly6 kernel for density
								float w = Poly6Kernel(r2, h2);
								density += boundary.Psi * Poly6Coeff * w;

								// Pressure gradient contribution from boundary
								float3 r = r_cm * CM_TO_M;
								float3 gradW = SpikyGradientFast(r, r2, h, h2);
								gradW *= SpikyCoeff * CM_TO_M;

								// Relative velocity damping: reduce pressure when boundary approaches fluid
								float pressureDampFactor = 1.0f;
								if (bEnableRelativeVelocityDamping)
								{
									float r_len = sqrt(r2_cm);
									if (r_len > SMALL_NUMBER)
									{
										float3 r_dir = r_cm / r_len;  // Direction from boundary to fluid
										float3 relVel = vel - boundary.Velocity;

										// Negative dot = boundary catching up (approaching)
										float approachSpeed = -dot(relVel, r_dir);

										// Damp pressure only when approaching (approachSpeed > 0)
										if (approachSpeed > 0.0f)
										{
											// Smooth falloff based on approach speed (cm/s)
											float dampAmount = saturate(approachSpeed / 1000.0f);
											pressureDampFactor = 1.0f - dampAmount * RelativeVelocityDampingStrength;
										}
									}
								}

								deltaP += pressureDampFactor * lambda_i_prev * boundary.Psi * gradW;
								
								//=============================================================
								// Boundary Velocity Transfer (moved from FluidApplyViscosity)
								// Fluid following moving boundaries - XSPH-style smoothing
								//=============================================================
								if (bEnableBoundaryVelocityTransfer && BoundaryAdhesionStrength > 0.0f)
								{
									float3 relativeVelocity = vel - boundary.Velocity;
									float relativeSpeed = length(relativeVelocity);

									// Detach factor: high relative speed = less transfer
									float detachFactor = smoothstep(BoundaryDetachSpeedThreshold, BoundaryMaxDetachSpeed, relativeSpeed);
									float transferFactor = (1.0f - detachFactor) * BoundaryVelocityTransferStrength;

									float3 velDiff = boundary.Velocity - vel;
									float contribution = w * boundary.Psi * BoundaryAdhesionStrength * transferFactor;
									boundaryVelCorrection += velDiff * contribution;
									boundaryVelWeight += contribution;
								}
							}
						}
					}
				}
			}
		}
		else
		{
			//=================================================================
			// Legacy Mode: O(M) brute-force (fallback)
			//=================================================================
			for (int bi = 0; bi < BoundaryParticleCount; ++bi)
			{
				FGPUBoundaryParticle boundary = BoundaryParticles[bi];
				float3 r_cm = pos - boundary.Position;
				float r2_cm = dot(r_cm, r_cm);
				float r2 = r2_cm * CM_TO_M_SQ;

			if (r2 < h2 && r2 > SMALL_NUMBER)
				{
					// Poly6 kernel for density
					float w = Poly6Kernel(r2, h2);
					density += boundary.Psi * Poly6Coeff * w;

					// Pressure gradient contribution from boundary
					float3 r = r_cm * CM_TO_M;
					float3 gradW = SpikyGradientFast(r, r2, h, h2);
					gradW *= SpikyCoeff * CM_TO_M;

					// Relative velocity damping: reduce pressure when boundary approaches fluid
					float pressureDampFactor = 1.0f;
					if (bEnableRelativeVelocityDamping)
					{
						float r_len = sqrt(r2_cm);
						if (r_len > SMALL_NUMBER)
						{
							float3 r_dir = r_cm / r_len;  // Direction from boundary to fluid
							float3 relVel = vel - boundary.Velocity;

							// Negative dot = boundary catching up (approaching)
							float approachSpeed = -dot(relVel, r_dir);

							// Damp pressure only when approaching (approachSpeed > 0)
							if (approachSpeed > 0.0f)
							{
								// Smooth falloff based on approach speed (cm/s)
								float dampAmount = saturate(approachSpeed / 1000.0f);
								pressureDampFactor = 1.0f - dampAmount * RelativeVelocityDampingStrength;
							}
						}
					}

					deltaP += pressureDampFactor * lambda_i_prev * boundary.Psi * gradW;
					
					//=============================================================
					// Boundary Velocity Transfer (moved from FluidApplyViscosity)
					// Fluid following moving boundaries - XSPH-style smoothing
					//=============================================================
					if (bEnableBoundaryVelocityTransfer && BoundaryAdhesionStrength > 0.0f)
					{
						float3 relativeVelocity = vel - boundary.Velocity;
						float relativeSpeed = length(relativeVelocity);

						// Detach factor: high relative speed = less transfer
						float detachFactor = smoothstep(BoundaryDetachSpeedThreshold, BoundaryMaxDetachSpeed, relativeSpeed);
						float transferFactor = (1.0f - detachFactor) * BoundaryVelocityTransferStrength;

						float3 velDiff = boundary.Velocity - vel;
						float contribution = w * boundary.Psi * BoundaryAdhesionStrength * transferFactor;
						boundaryVelCorrection += velDiff * contribution;
						boundaryVelWeight += contribution;
					}
				}
			}
		}
	}
	
	//=========================================================================
	// Apply Boundary Velocity Transfer
	// Scale by 1/SolverIterationCount to avoid over-application in multi-iteration solver
	// Skip for NEAR_BOUNDARY particles (they follow bone velocity)
	//=========================================================================
	if (boundaryVelWeight > SMALL_NUMBER && SolverIterationCount > 0 && !bIsNearBoundary)
	{
		float iterationScale = 1.0f / (float)SolverIterationCount;
		vel += (boundaryVelCorrection / boundaryVelWeight) * iterationScale;
	}

	//=========================================
	// Calculate NEW Lambda (XPBD formulation)
	//=========================================
	float C = (density * invRestDensity) - 1.0f;
	float alphaTilde = Compliance / max(DeltaTimeSq, 0.00001f);

	float lambda = lambda_i_prev;
	if (C > 0.0f)
	{
		float deltaLambda = (-C - alphaTilde * lambda_i_prev) / (sumGradC2 + alphaTilde);
		lambda = lambda_i_prev + deltaLambda;
	}
	// If C <= 0, keep previous Lambda

	//=========================================
	// Apply position correction
	// PBF formula: Δp = (1/ρ₀) × Σⱼ (λᵢ + λⱼ + s_corr) × ∇W
	// This is a SUM over neighbors, not an average
	float3 deltaP_cm = deltaP * invRestDensity;
	pos += deltaP_cm;

	//=========================================
	// Apply Position-Based Surface Tension
	// SurfaceTensionSurfaceThreshold > 0: Surface particles only (water-like)
	// SurfaceTensionSurfaceThreshold == 0: All particles (jelly-like)
	// Skip for NEAR_BOUNDARY particles (they follow bone position)
	//=========================================
	float deltaTime = sqrt(max(DeltaTimeSq, 0.0001f));  // Recover DeltaTime from DeltaTimeSq
	float invDeltaTime = 1.0f / deltaTime;

	if (surfaceTensionConstraintCount > 0 && !bIsNearBoundary)
	{
		float3 avgSTCorrection = surfaceTensionCorrection / (float)surfaceTensionConstraintCount;

		// Clamp for stability
		float stCorrLen = length(avgSTCorrection);
		if (stCorrLen > MaxSurfaceTensionCorrection && stCorrLen > SMALL_NUMBER)
		{
			avgSTCorrection = avgSTCorrection * (MaxSurfaceTensionCorrection / stCorrLen);
		}

		// Surface scaling: only when SurfaceTensionSurfaceThreshold > 0
		float surfaceScale = 1.0f;
		if (SurfaceTensionSurfaceThreshold > 0)
		{
			// Surface particles (fewer neighbors) get full ST, interior gets less
			float surfaceRatio = saturate((float)neighborCount / (float)SurfaceTensionSurfaceThreshold);
			surfaceScale = 1.0f - surfaceRatio;
			surfaceScale = sqrt(surfaceScale);  // Smooth transition
		}
		// When SurfaceTensionSurfaceThreshold == 0, surfaceScale = 1.0 (all particles)

		if (surfaceScale > 0.01f)
		{
			float relaxation = 1.0f - SurfaceTensionVelocityDamping;
			float3 posCorrection = avgSTCorrection * surfaceScale * relaxation;
			pos += posCorrection;
			// Also update velocity to match position change (for viscosity compatibility)
			vel += posCorrection * invDeltaTime;
		}
	}

	// Write back to SOA buffers
	// Position: still float3 (precision critical for simulation stability)
	PredictedPositions[idx3] = pos.x;
	PredictedPositions[idx3 + 1] = pos.y;
	PredictedPositions[idx3 + 2] = pos.z;

	// Velocity: packed half3 (bandwidth optimization)
	PackedVelocities[idx] = PackVelocity(vel);

	// Density + Lambda: packed half2 (bandwidth optimization)
	PackedDensityLambda[idx] = PackDensityLambda(density, lambda);

	NeighborCountsBuffer[idx] = neighborCount;
}
